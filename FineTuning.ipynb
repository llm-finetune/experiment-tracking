{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjAd3VHVSD8xdhC6QmD69n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fine tuning Model**"
      ],
      "metadata": {
        "id": "qbsyAkjDaO4T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8v_vmRYaMgY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U bitsandbytes\n",
        "%pip install -U transformers\n",
        "%pip install -U peft\n",
        "%pip install -U accelerate\n",
        "%pip install -U trl\n",
        "%pip install dill\n",
        "%pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "secret_hf = userdata.get('HF_TOKEN')\n",
        "login(\n",
        "#  token=\"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\", # ADD YOUR TOKEN HERE\n",
        "  token=secret_hf, # ADD YOUR TOKEN HERE\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "a4bSJ6dfabiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch, wandb\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "SVLIJs6CRL_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "secret_wandb = userdata.get('wandb')\n",
        "wandb.login(key = secret_wandb)\n",
        "run = wandb.init(\n",
        "    project='Fine tuning Experiments',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")"
      ],
      "metadata": {
        "id": "WdPwlHOYU2Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"Qwen/Qwen1.5-0.5B\"\n",
        "dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
        "new_model = \"Qwen1.5-0.5B_acqku\""
      ],
      "metadata": {
        "id": "tI_UY-Jnax8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the dataset\n",
        "#dataset = load_dataset(dataset_name, split=\"train[0:400]\")\n",
        "dataset = load_dataset(dataset_name, split=\"train[0:400]\")\n",
        "dataset[\"text\"][100]"
      ],
      "metadata": {
        "id": "3d7HzJmPa0qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit= True,\n",
        "    bnb_4bit_quant_type= \"nf4\",\n",
        "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant= False,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model,\n",
        "        load_in_4bit=True,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        ")\n",
        "model.config.use_cache = False # silence the warnings\n",
        "model.config.pretraining_tp = 1\n",
        "model.gradient_checkpointing_enable()"
      ],
      "metadata": {
        "id": "V54-qzEze7cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_eos_token = True\n",
        "#tokenizer.add_bos_token, tokenizer.add_eos_token\n",
        "tokenizer.add_eos_token"
      ],
      "metadata": {
        "id": "YJg7GAwZa8nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_kbit_training(model)\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "J9q9KLzHa_De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=25,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    gradient_checkpointing=True,  # Leads to reduction in memory at slighly decrease in speed ## Added Later\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": True},   ## Added later\n",
        "    report_to=\"wandb\"\n",
        ")"
      ],
      "metadata": {
        "id": "Us0xo0c3gMWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= None,\n",
        "    dataset_text_field=\"text\",\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        ")"
      ],
      "metadata": {
        "id": "A4CIcUCAgTcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "krYpspdhbGLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "id": "uqqFAmN6bIT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.save(new_model)"
      ],
      "metadata": {
        "id": "VD_FNJAFbK4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()\n",
        "model.config.use_cache = True"
      ],
      "metadata": {
        "id": "7DTUwsA3bNEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.push_to_hub(new_model, use_temp_dir=False)"
      ],
      "metadata": {
        "id": "JVv773QsbPQ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}