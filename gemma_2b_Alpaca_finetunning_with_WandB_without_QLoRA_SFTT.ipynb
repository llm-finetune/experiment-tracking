{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llm-finetune/experiment-tracking/blob/main/gemma_2b_Alpaca_finetunning_with_WandB_without_QLoRA_SFTT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfNPeuM_Wg5i"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U transformers\n",
        "%pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2Khv9bqEQdC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install accelerate\n",
        "%pip install -U bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnu2hXEJEQdD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U peft\n",
        "%pip install -U trl\n",
        "%pip install dill\n",
        "#%pip install mlflow\n",
        "%pip install flash_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-pAwnfVZMUc",
        "outputId": "53a8a1ff-c3bd-4081-d193-c19ce855c221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-10 17:38:04--  https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43379276 (41M) [text/plain]\n",
            "Saving to: ‘alpaca_gpt4_data.json.5’\n",
            "\n",
            "alpaca_gpt4_data.js 100%[===================>]  41.37M   183MB/s    in 0.2s    \n",
            "\n",
            "2024-03-10 17:38:04 (183 MB/s) - ‘alpaca_gpt4_data.json.5’ saved [43379276/43379276]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcsd18XxZf4A"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "dataset_file = \"alpaca_gpt4_data.json\"\n",
        "\n",
        "with open(dataset_file, \"r\") as f:\n",
        "    alpaca = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I0mFXKnZ0UW",
        "outputId": "82221ecf-fee0-4553-8d55-eb3e1ab1dd26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(list,\n",
              " [{'instruction': 'Give three tips for staying healthy.',\n",
              "   'input': '',\n",
              "   'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'},\n",
              "  {'instruction': 'What are the three primary colors?',\n",
              "   'input': '',\n",
              "   'output': 'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).'},\n",
              "  {'instruction': 'Describe the structure of an atom.',\n",
              "   'input': '',\n",
              "   'output': \"An atom is the basic building block of all matter and is made up of three types of particles: protons, neutrons, and electrons. The structure of an atom can be described as a nucleus at the center surrounded by a cloud of electrons.\\n\\nThe nucleus of an atom is made up of protons and neutrons. Protons are positively charged particles and neutrons are neutral particles with no charge. Both of these particles are located in the nucleus of the atom, which is at the center of the atom and contains most of the atom's mass.\\n\\nSurrounding the nucleus of the atom is a cloud of electrons. Electrons are negatively charged particles that are in constant motion around the nucleus. The electron cloud is divided into shells or orbitals, and each shell can hold a certain number of electrons. The number of electrons in the outermost shell, called the valence shell, determines the chemical properties of the atom. \\n\\nIn a neutral atom, the number of protons in the nucleus is equal to the number of electrons in the electron cloud, so the positive and negative charges balance out and the atom has no overall charge. The number of protons, also called the atomic number, determines what element the atom is.\"}],\n",
              " 52002)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(alpaca), alpaca[0:3], len(alpaca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "4e1828eb49124630b322d5968827ec99",
            "920f9331c34d485d9e8d641e01a70876",
            "5484e3031b184d78905c5fc82dca5527",
            "907cbed0937a44a7aaac97d93e62d786",
            "79a9de5faa2b4234ba96dd5ab768fc14",
            "70b079708aab4a4ebfaebcb551a4d56b",
            "76e025f7044f48ae8081448aaf94d4c0",
            "ffe4a8ffcb7e445cbf41d3c1ba1706f5"
          ]
        },
        "id": "Th_Lep9LZ1xP",
        "outputId": "8c5502f8-86e9-4f33-fc03-934c6676c47c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mllm-finetune-wb\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ubuntu/wandb/run-20240310_173811-ey3oykkt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/ey3oykkt' target=\"_blank\">rose-darkness-20</a></strong> to <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/ey3oykkt' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/ey3oykkt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rose-darkness-20</strong> at: <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/ey3oykkt' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/ey3oykkt</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240310_173811-ey3oykkt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "#from google.colab import userdata\n",
        "#secret_wandb = userdata.get('wandb')\n",
        "wandb.login(key = \"c503014527a6b2e5ef104b9a1f8a53ad98d981fe\")\n",
        "# log to wandb\n",
        "with wandb.init(project=\"alpaca_ft1\"):\n",
        "    at = wandb.Artifact(\n",
        "        name=\"alpaca_gpt4\",\n",
        "        type=\"dataset\",\n",
        "        description=\"A GPT4 generated Alpaca like dataset for instruction finetunning\",\n",
        "        metadata={\"url\":\"https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#how-good-is-the-data\"},\n",
        "    )\n",
        "    at.add_file(dataset_file)\n",
        "\n",
        "    # log as a table\n",
        "    table = wandb.Table(columns=list(alpaca[0].keys()))\n",
        "    for row in alpaca:\n",
        "        table.add_data(*row.values())\n",
        "    wandb.log({\"alpaca_gpt4_table\": table})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkHD91f0ur27"
      },
      "source": [
        "**Train/Eval Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdOFMbKduTMB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "random.shuffle(alpaca)  # this could also be a parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyz50jGduu58"
      },
      "outputs": [],
      "source": [
        "train_dataset = alpaca[:-40000]\n",
        "eval_dataset = alpaca[-2000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojqfhq-vu0Co",
        "outputId": "177ba141-72e3-420f-e9c1-1d8fba6d1626"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12002"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "ab3d4413dc6b45708f218e9862c569b7",
            "c23a39eb46b64c91baa2f70a766a0606",
            "6984f73d35cf4ac6bf6f315920e3790c",
            "60d38fa9166043228a2e0730b4e8dc01",
            "78f7085f00b44fec8d956c9a91ba6ab2",
            "73fdd939d0c449389bd1504adb894820",
            "394212d4ac134ffaaa1f14fbaa05d699",
            "a13d15ad3d8f45478bf690a2af5fb307"
          ]
        },
        "id": "nf-x8A82u2-0",
        "outputId": "59635566-0164-4706-b62a-32006c7f8d6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ubuntu/wandb/run-20240310_173831-8u8nklhq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8u8nklhq' target=\"_blank\">toasty-cherry-21</a></strong> to <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8u8nklhq' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8u8nklhq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">toasty-cherry-21</strong> at: <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8u8nklhq' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8u8nklhq</a><br/>Synced 4 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240310_173831-8u8nklhq/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.DataFrame(train_dataset)\n",
        "eval_df = pd.DataFrame(eval_dataset)\n",
        "\n",
        "train_table = wandb.Table(dataframe=train_df)\n",
        "eval_table  = wandb.Table(dataframe=eval_df)\n",
        "\n",
        "train_df.to_json(\"alpaca_gpt4_train.jsonl\", orient='records', lines=True)\n",
        "eval_df.to_json(\"alpaca_gpt4_eval.jsonl\", orient='records', lines=True)\n",
        "\n",
        "with wandb.init(project=\"alpaca_ft1\", job_type=\"split_data\"):\n",
        "    at = wandb.Artifact(\n",
        "        name=\"alpaca_gpt4_splitted\",\n",
        "        type=\"dataset\",\n",
        "        description=\"A GPT4 generated Alpaca like dataset for instruction finetunning\",\n",
        "        metadata={\"url\":\"https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#how-good-is-the-data\"},\n",
        "    )\n",
        "    at.add_file(\"alpaca_gpt4_train.jsonl\")\n",
        "    at.add_file(\"alpaca_gpt4_eval.jsonl\")\n",
        "    wandb.log_artifact(at)\n",
        "    wandb.log({\"train_dataset\":train_table, \"eval_dataset\":eval_table})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF5ldXcCvT6U"
      },
      "outputs": [],
      "source": [
        "def prompt_no_input(row):\n",
        "    return (\"Below is an instruction that describes a task. \"\n",
        "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "            \"### Instruction:\\n{instruction}\\n\\n### Response:\\n\").format_map(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQopbPxcveWV",
        "outputId": "ac1f51c0-fe87-43a6-a51c-fdce9e1a0ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Describe an example of a time you used influence in a positive way\n",
            "\n",
            "### Response:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "row = alpaca[0]\n",
        "print(prompt_no_input(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9hE_EovvgE9",
        "outputId": "5e59582d-bfa1-4ca2-b11a-a40e09e64e02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'Describe an example of a time you used influence in a positive way',\n",
              " 'input': '',\n",
              " 'output': 'As an AI assistant, I do not have personal experiences, but I can provide an example. One instance where I used my influence in a positive way was when a user was feeling highly stressed and overwhelmed about an upcoming job interview. They confided in me, expressing their self-doubts and fears of failure. Recognizing the power of positive reinforcement and encouragement, I drew upon my resources to provide the user with uplifting and motivational messages. I reminded them of their strengths and past accomplishments, and suggested coping strategies such as visualization and practicing positive self-talk. Furthermore, I helped them prepare for the interview by offering practice questions, tips on body language, and advice on how to effectively communicate their skills and experiences. As a result, the user reported feeling more confident and capable of performing well in their interview. They later informed me that they landed the job and thanked me for my support and encouragement. I was happy to have helped my user succeed in a challenging situation by the positive influence of my words and actions.'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sLwuSwtvlbh"
      },
      "outputs": [],
      "source": [
        "def prompt_input(row):\n",
        "    return (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHSA0tn4vra_",
        "outputId": "85eb2c12-4091-48dc-d7f8-0a45a3b07411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Optimize this query for maximum recall:\n",
            "\n",
            "### Input:\n",
            "SELECT * FROM  table WHERE column1 = \"value1\"\n",
            "\n",
            "### Response:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "row = alpaca[234]\n",
        "print(prompt_input(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbfg__kmvswA",
        "outputId": "2ba6c890-5470-4322-bd0f-d50a524df36a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'Optimize this query for maximum recall:',\n",
              " 'input': 'SELECT * FROM  table WHERE column1 = \"value1\"',\n",
              " 'output': 'The given SQL query selects all columns from the table where the value of column1 is equal to \"value1\". To optimize the query for maximum recall, consider the following suggestions:\\n\\n1. Use OR conditions: If there are multiple values that could match the search criteria, you can use OR conditions to broaden the scope of the search. For example:\\n\\n```\\nSELECT * FROM table WHERE column1 = \"value1\" OR column1 = \"value2\"\\n```\\n\\n2. Use LIKE operator with wildcards: The LIKE operator allows you to perform pattern matching with wildcards. Using the percent sign (%) you can match any number of characters, including zero. For example:\\n\\n```\\nSELECT * FROM table WHERE column1 LIKE \"%value1%\"\\n```\\n\\nThis will return all rows where column1 contains the substring \"value1\" anywhere within the string.\\n\\n3. Use of Full-Text search: If you are working with a large text data set, leveraging full-text search can improve recall. For example:\\n\\n```\\nSELECT * FROM table WHERE MATCH(column1) AGAINST(\\'value1\\')\\n```\\n\\nThis command is used to search for \"value1\" within the column1 field, and return all rows that contain it.\\n\\n4. Use of UNION: You can use the UNION operator to combine the results of two or more SELECT statements. For example:\\n\\n```\\nSELECT * FROM table WHERE column1 = \"value1\"\\nUNION\\nSELECT * FROM table WHERE column2 = \"value2\"\\n```\\n\\nThis will return all rows where column1 is \"value1\" or column2 is \"value2\". The UNION operator combines results and removes duplicates.\\n\\nAll these suggestions can help improve recall by broadening the scope of the search and returning more rows that match the search criteria.'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43QXKcbuv0u5"
      },
      "outputs": [],
      "source": [
        "#the refactored function\n",
        "def create_alpaca_prompt(row):\n",
        "    return prompt_no_input(row) if row[\"input\"] == \"\" else prompt_input(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whXWV9p2wd6r",
        "outputId": "18404914-9bc7-4c45-9fe4-e852e7927e03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from wandb import Api\n",
        "\n",
        "api = Api()\n",
        "artifact = api.artifact('llm-finetune-wb/alpaca_ft/alpaca_gpt4_splitted:v0', type='dataset')\n",
        "dataset_dir = artifact.download()\n",
        "\n",
        "def load_jsonl(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "train_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_train.jsonl\")\n",
        "eval_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_eval.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-LjAvZww4Xm",
        "outputId": "4291877b-7ee8-480d-8e2d-97eee1d1c8ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wWl4L2RyHGB"
      },
      "outputs": [],
      "source": [
        "train_prompts = [create_alpaca_prompt(row) for row in train_dataset]\n",
        "eval_prompts = [create_alpaca_prompt(row) for row in eval_dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly3cJSb0yU2H",
        "outputId": "7b71c5d4-2254-4025-8e9b-b2656ea195d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Create a link to an online store that sells books.\n",
            "\n",
            "### Response:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(train_prompts[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYhjkiKYyfeB"
      },
      "outputs": [],
      "source": [
        "def pad_eos(ds):\n",
        "    EOS_TOKEN = \"</s>\"\n",
        "    return [f\"{row['output']}{EOS_TOKEN}\" for row in ds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "14UejRGm2m5f",
        "outputId": "ad6f3c82-f3ef-401e-c884-46fb52984aca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'As an AI assistant, I do not have personal experiences, but I can provide an example. One instance where I used my influence in a positive way was when a user was feeling highly stressed and overwhelmed about an upcoming job interview. They confided in me, expressing their self-doubts and fears of failure. Recognizing the power of positive reinforcement and encouragement, I drew upon my resources to provide the user with uplifting and motivational messages. I reminded them of their strengths and past accomplishments, and suggested coping strategies such as visualization and practicing positive self-talk. Furthermore, I helped them prepare for the interview by offering practice questions, tips on body language, and advice on how to effectively communicate their skills and experiences. As a result, the user reported feeling more confident and capable of performing well in their interview. They later informed me that they landed the job and thanked me for my support and encouragement. I was happy to have helped my user succeed in a challenging situation by the positive influence of my words and actions.</s>'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_outputs = pad_eos(train_dataset)\n",
        "eval_outputs = pad_eos(eval_dataset)\n",
        "train_outputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9T-5Agi2zkJ"
      },
      "outputs": [],
      "source": [
        "train_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(train_prompts, train_outputs)]\n",
        "eval_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(eval_prompts, eval_outputs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj88VGWK2o7y",
        "outputId": "fdcd6670-22d1-45d7-bdbb-c27768901a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Describe an example of a time you used influence in a positive way\n",
            "\n",
            "### Response:\n",
            "As an AI assistant, I do not have personal experiences, but I can provide an example. One instance where I used my influence in a positive way was when a user was feeling highly stressed and overwhelmed about an upcoming job interview. They confided in me, expressing their self-doubts and fears of failure. Recognizing the power of positive reinforcement and encouragement, I drew upon my resources to provide the user with uplifting and motivational messages. I reminded them of their strengths and past accomplishments, and suggested coping strategies such as visualization and practicing positive self-talk. Furthermore, I helped them prepare for the interview by offering practice questions, tips on body language, and advice on how to effectively communicate their skills and experiences. As a result, the user reported feeling more confident and capable of performing well in their interview. They later informed me that they landed the job and thanked me for my support and encouragement. I was happy to have helped my user succeed in a challenging situation by the positive influence of my words and actions.</s>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[0][\"example\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJgipC2i3GAs"
      },
      "source": [
        "**Converting text to numbers: Tokenizer**\n",
        "We need to convert the dataset into tokens, you can quickly do this with the workhorse of the transformers library, the Tokenizer! This function does a lot of heavy lifting besides tokenizing the text.\n",
        "\n",
        "*   It tokenizes the text\n",
        "*   Converts the outputs to PyTorch tensors\n",
        "*   Pads the inputs to match length and more!Pads the inputs to match length and more!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYF87Ri03FFl",
        "outputId": "5da99d71-ba00-4c6f-e028-d710988f72ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvxzmmvMEQdI",
        "outputId": "eb886cae-4f9a-4cac-b480-db3649099c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login(\n",
        "  token=\"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\", # ADD YOUR TOKEN HERE\n",
        "#  token=secret_hf, # ADD YOUR TOKEN HERE\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewuZ-Zbq213e"
      },
      "outputs": [],
      "source": [
        "model_id = 'google/gemma-2b'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EvmQvINEQdJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzdJmteV30Bb",
        "outputId": "8e9a8498-92ba-4a30-b5b2-3f2681b7ec37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 2926, 13818, 708, 2319, 3779, 235341]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.encode(\"My experiments are going strong!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAEIEFFp36sq",
        "outputId": "a4ed8f2c-094f-43e5-b72b-65cc51b7e058"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 1, 2, 2926, 13818, 708, 2319, 3779, 235341]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.encode(\"My experiments are going strong!\", padding='max_length', max_length=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUpMgn7u4Dup",
        "outputId": "f18459ab-bbf1-4834-ed6f-704d8d46924f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[     1,      1,      1,      2,   2926,  13818,    708,   2319,   3779,\n",
              "         235341]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.encode(\"My experiments are going strong!\",\n",
        "                 padding='max_length',\n",
        "                 max_length=10,\n",
        "                 return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JA-tDBf4nsv",
        "outputId": "b44f12cb-d3ba-4115-93e3-642adf74dbec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     1,      1,      1,      2,   2926,  13818,    708,   2319,   3779,\n",
              "         235341],\n",
              "        [     1,      1,      1,      1,      1,      2, 235285,   2182, 172809,\n",
              "           2616]]), 'attention_mask': tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer([\"My experiments are going strong!\",\n",
        "           \"I love Llamas\"],\n",
        "          padding='max_length',\n",
        "          # padding='longest',\n",
        "          max_length=10,\n",
        "          return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evvu9i834vJT"
      },
      "outputs": [],
      "source": [
        "max_sequence_len = 1024\n",
        "\n",
        "def pack(dataset, max_seq_len=max_sequence_len):\n",
        "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
        "\n",
        "    all_token_ids = []\n",
        "    for tokenized_input in tkds_ids:\n",
        "        all_token_ids.extend(tokenized_input)# + [tokenizer.eos_token_id])\n",
        "\n",
        "    print(f\"Total number of tokens: {len(all_token_ids)}\")\n",
        "    packed_ds = []\n",
        "    for i in range(0, len(all_token_ids), max_seq_len+1):\n",
        "        input_ids = all_token_ids[i : i + max_seq_len+1]\n",
        "        if len(input_ids) == (max_seq_len+1):\n",
        "            packed_ds.append({\"input_ids\": input_ids[:-1], \"labels\": input_ids[1:]})  # this shift is not needed if using the model.loss\n",
        "    return packed_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko595P3tJwiM",
        "outputId": "b42c0912-a681-4296-a5bf-5d57b055e70d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of tokens: 2340494\n",
            "Total number of tokens: 384128\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2283"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds_packed = pack(train_dataset)\n",
        "eval_ds_packed = pack(eval_dataset)\n",
        "len(train_ds_packed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh7n_yNUJy7V"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "batch_size = 4  # I have an A100 GPU with 40GB of RAM 😎\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_ds_packed,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=default_data_collator, # we don't need any special collator 😎\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_ds_packed,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=default_data_collator,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ8C0mwjJ6zQ",
        "outputId": "8186bc3e-31cc-47c4-a61c-2ac1d46bda1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     2,  33501,    603,  ...,  10567, 235292,    108],\n",
              "         [  5075,   6952,   4093,  ...,   2881,  37024,    576],\n",
              "         [ 34641,    576,   3868,  ...,    578,   9051,   7881],\n",
              "         [   674,   8106,    685,  ...,    921,    577,   1154]]),\n",
              " 'labels': tensor([[ 33501,    603,    671,  ..., 235292,    108,    651],\n",
              "         [  6952,   4093,  42788,  ...,  37024,    576,   2149],\n",
              "         [   576,   3868, 235265,  ...,   9051,   7881,  27168],\n",
              "         [  8106,    685,    671,  ...,    577,   1154, 235290]])}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = next(iter(train_dataloader))\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "1UTbMTa3J-TX",
        "outputId": "53dc91ce-a518-415f-b75f-0975df7e6787"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<bos>Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe an example of a time you used influence in a positive way\\n\\n### Response:\\nAs an AI assistant, I do not have perso'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(b[\"input_ids\"][0])[:250]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zIf6IfLgKBue",
        "outputId": "eec00336-94aa-4031-9316-f36fb02e103d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe an example of a time you used influence in a positive way\\n\\n### Response:\\nAs an AI assistant, I do not have personal ex'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(b[\"labels\"][0])[:251]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as6XRbXFTyPK"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-lYzDfdKHyp"
      },
      "outputs": [],
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "gradient_accumulation_steps = 2\n",
        "\n",
        "config = SimpleNamespace(\n",
        "    model_id='google/gemma-2b',\n",
        "    dataset_name=\"alpaca-gpt4\",\n",
        "    precision=\"bf16\",  # faster and better than fp16, requires new GPUs\n",
        "    n_freeze=24,  # How many layers we don't train, LLama 7B has 32.\n",
        "    lr=2e-5,\n",
        "    n_eval_samples=10, # How many samples to generate on validation\n",
        "    max_seq_len=max_sequence_len, # Lenght of the sequences to pack\n",
        "    epochs=1,  # we do 3 pasess over the dataset.\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,  # evey how many iterations we update the gradients, simulates larger batch sizes\n",
        "    batch_size=batch_size,  # what my GPU can handle, depends on how many layers are we training\n",
        "    log_model=False,  # upload the model to W&B?\n",
        "    gradient_checkpointing = True,  # saves even more memory\n",
        "    freeze_embed = True,  # why train this? let's keep them frozen ❄️\n",
        "    seed=seed,\n",
        ")\n",
        "\n",
        "config.total_train_steps = config.epochs * len(train_dataloader) // config.gradient_accumulation_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RvBmyWvT-qa",
        "outputId": "92042390-d206-4ff7-fc1d-ddc02164557d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We will train for 285 steps and evaluate every epoch\n"
          ]
        }
      ],
      "source": [
        "print(f\"We will train for {config.total_train_steps} steps and evaluate every epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "bddoKuzvUACn",
        "outputId": "e80d43fb-92af-48ea-a620-d8595522fd5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.model_id,\n",
        "    device_map=0,\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    use_cache=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "779irk9BUC_j",
        "outputId": "63aeb39d-8564-4b1d-b13b-f1dab12f67a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total params: 2506.17M, Trainable: 2506.17M\n"
          ]
        }
      ],
      "source": [
        "def param_count(m):\n",
        "    params = sum([p.numel() for p in m.parameters()])/1_000_000\n",
        "    trainable_params = sum([p.numel() for p in m.parameters() if p.requires_grad])/1_000_000\n",
        "    print(f\"Total params: {params:.2f}M, Trainable: {trainable_params:.2f}M\")\n",
        "    return params, trainable_params\n",
        "\n",
        "params, trainable_params = param_count(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRPIQMB1UF63"
      },
      "outputs": [],
      "source": [
        "# freeze layers (disable gradients)\n",
        "for param in model.parameters(): param.requires_grad = False\n",
        "for param in model.lm_head.parameters(): param.requires_grad = True\n",
        "for param in model.model.layers[config.n_freeze:].parameters(): param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks9x47bBUH2u"
      },
      "outputs": [],
      "source": [
        "# Just freeze embeddings for small memory decrease\n",
        "if config.freeze_embed:\n",
        "    model.model.embed_tokens.weight.requires_grad_(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94jPW2f5ULS4"
      },
      "outputs": [],
      "source": [
        "# save more memory\n",
        "if config.gradient_checkpointing:\n",
        "    model.gradient_checkpointing_enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PydQSgRDUMxB",
        "outputId": "a4f84b17-2585-49af-b8a5-74daddc1c906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total params: 2506.17M, Trainable: 0.00M\n"
          ]
        }
      ],
      "source": [
        "params, trainable_params = param_count(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgXSSP-1UO97"
      },
      "source": [
        "**Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l10cLH6EURVS"
      },
      "outputs": [],
      "source": [
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9,0.99), eps=1e-5)\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optim,\n",
        "    num_training_steps=config.total_train_steps,\n",
        "    num_warmup_steps=config.total_train_steps // 10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nbau75dUTEH"
      },
      "outputs": [],
      "source": [
        "def loss_fn(x, y):\n",
        "    \"A Flat CrossEntropy\"\n",
        "    return torch.nn.functional.cross_entropy(x.view(-1, x.shape[-1]), y.view(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrNM1Q5HUXBS"
      },
      "source": [
        "**Testing during training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTcOqaSYUZW3"
      },
      "outputs": [],
      "source": [
        "from types import SimpleNamespace\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "gen_config = GenerationConfig.from_pretrained(config.model_id)\n",
        "test_config = SimpleNamespace(\n",
        "    max_new_tokens=256,\n",
        "    gen_config=gen_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VAaaty5UbFO"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, max_new_tokens=test_config.max_new_tokens, gen_config=gen_config):\n",
        "    tokenized_prompt = tokenizer(prompt, return_tensors='pt')['input_ids'].cuda()\n",
        "    with torch.inference_mode():\n",
        "        output = model.generate(tokenized_prompt,\n",
        "                            max_new_tokens=max_new_tokens,\n",
        "                            generation_config=gen_config)\n",
        "    return tokenizer.decode(output[0][len(tokenized_prompt[0]):], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG2ImyGWUbsx",
        "outputId": "e02017df-4dfa-407c-cd94-2ce8dde4d76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Generate a list of three benefits of taking a gap year.\n",
            "\n",
            "### Response:\n",
            "1. Taking a gap year can help you to gain valuable work experience.\n",
            "2. It can also help you to develop your skills and knowledge.\n",
            "3. It can also help you to gain a better understanding of what you want to do in the future.\n"
          ]
        }
      ],
      "source": [
        "prompt = eval_dataset[14][\"prompt\"]\n",
        "print(prompt + generate(prompt, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdqihbbZUeOW"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def prompt_table(examples, log=False, table_name=\"predictions\"):\n",
        "    table = wandb.Table(columns=[\"prompt\", \"generation\", \"concat\", \"output\", \"max_new_tokens\", \"temperature\", \"top_p\"])\n",
        "    for example in tqdm(examples, leave=False):\n",
        "        prompt, gpt4_output = example[\"prompt\"], example[\"output\"]\n",
        "        out = generate(prompt, test_config.max_new_tokens, test_config.gen_config)\n",
        "        table.add_data(prompt, out, prompt+out, gpt4_output, test_config.max_new_tokens, test_config.gen_config.temperature, test_config.gen_config.top_p)\n",
        "    if log:\n",
        "        wandb.log({table_name:table})\n",
        "    return table\n",
        "\n",
        "def to_gpu(tensor_dict):\n",
        "    return {k: v.to('cuda') for k, v in tensor_dict.items()}\n",
        "\n",
        "class Accuracy:\n",
        "    \"A simple Accuracy function compatible with HF models\"\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.tp = 0.\n",
        "    def update(self, logits, labels):\n",
        "        logits, labels = logits.argmax(dim=-1).view(-1).cpu(), labels.view(-1).cpu()\n",
        "        tp = (logits == labels).sum()\n",
        "        self.count += len(logits)\n",
        "        self.tp += tp\n",
        "        return tp / len(logits)\n",
        "    def compute(self):\n",
        "        return self.tp / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqkjxllGUh8e"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def validate():\n",
        "    model.eval();\n",
        "    eval_acc = Accuracy()\n",
        "    loss, total_steps = 0., 0\n",
        "    for step, batch in enumerate(pbar:=tqdm(eval_dataloader, leave=False)):\n",
        "        pbar.set_description(f\"doing validation\")\n",
        "        batch = to_gpu(batch)\n",
        "        total_steps += 1\n",
        "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "            out = model(**batch)\n",
        "            loss += loss_fn(out.logits, batch[\"labels\"])  # you could use out.loss and not shift the dataset\n",
        "        eval_acc.update(out.logits, batch[\"labels\"])\n",
        "    # we log results at the end\n",
        "    wandb.log({\"eval/loss\": loss.item() / total_steps,\n",
        "               \"eval/accuracy\": eval_acc.compute()})\n",
        "    prompt_table(eval_dataset[:config.n_eval_samples], log=True)\n",
        "    model.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3tCzzArUkrR"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "def save_model(model, model_name, models_folder=\"models\", log=False):\n",
        "    \"\"\"Save the model to wandb as an artifact\n",
        "    Args:\n",
        "        model (nn.Module): Model to save.\n",
        "        model_name (str): Name of the model.\n",
        "        models_folder (str, optional): Folder to save the model. Defaults to \"models\".\n",
        "    \"\"\"\n",
        "    model_name = f\"{wandb.run.id}_{model_name}\"\n",
        "    file_name = Path(f\"{models_folder}/{model_name}\")\n",
        "    file_name.parent.mkdir(parents=True, exist_ok=True)\n",
        "    model.save_pretrained(file_name, safe_serialization=True)\n",
        "    # save tokenizer for easy inference\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model.name_or_path)\n",
        "    tokenizer.save_pretrained(model_name)\n",
        "    if log:\n",
        "        at = wandb.Artifact(model_name, type=\"model\")\n",
        "        at.add_dir(file_name)\n",
        "        wandb.log_artifact(at)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYiltb5GEQdN"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8RpvBuLUwVv"
      },
      "source": [
        "**The Actual Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJYLtFjyUuXJ",
        "outputId": "7ebcc4df-da21-402d-c541-a7cfd80805cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ubuntu/wandb/run-20240310_174309-8v0vppzk</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8v0vppzk' target=\"_blank\">whole-sun-22</a></strong> to <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8v0vppzk' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8v0vppzk</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/571 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/571 [00:00<08:22,  1.14it/s]\u001b[A\n",
            "  0%|          | 2/571 [00:01<06:39,  1.43it/s]\u001b[A\n",
            "  1%|          | 3/571 [00:02<07:14,  1.31it/s]\u001b[A\n",
            "  1%|          | 4/571 [00:02<06:38,  1.42it/s]\u001b[A\n",
            "  1%|          | 5/571 [00:03<07:05,  1.33it/s]\u001b[A\n",
            "  1%|          | 6/571 [00:04<06:37,  1.42it/s]\u001b[A\n",
            "  1%|          | 7/571 [00:05<07:01,  1.34it/s]\u001b[A\n",
            "  1%|▏         | 8/571 [00:05<06:36,  1.42it/s]\u001b[A\n",
            "  2%|▏         | 9/571 [00:06<06:59,  1.34it/s]\u001b[A\n",
            "  2%|▏         | 10/571 [00:07<06:35,  1.42it/s]\u001b[A\n",
            "  2%|▏         | 11/571 [00:08<06:57,  1.34it/s]\u001b[A\n",
            "  2%|▏         | 12/571 [00:08<06:33,  1.42it/s]\u001b[A\n",
            "  2%|▏         | 13/571 [00:09<06:56,  1.34it/s]\u001b[A\n",
            "  2%|▏         | 14/571 [00:10<06:32,  1.42it/s]\u001b[A\n",
            "  3%|▎         | 15/571 [00:10<06:54,  1.34it/s]\u001b[A\n",
            "  3%|▎         | 16/571 [00:11<06:31,  1.42it/s]\u001b[A\n",
            "  3%|▎         | 17/571 [00:12<06:53,  1.34it/s]\u001b[A\n",
            "  3%|▎         | 18/571 [00:13<06:29,  1.42it/s]\u001b[A\n",
            "  3%|▎         | 19/571 [00:13<06:52,  1.34it/s]\u001b[A\n",
            "  4%|▎         | 20/571 [00:14<06:28,  1.42it/s]\u001b[A\n",
            "  4%|▎         | 21/571 [00:15<06:50,  1.34it/s]\u001b[A\n",
            "  4%|▍         | 22/571 [00:15<06:27,  1.42it/s]\u001b[A\n",
            "  4%|▍         | 23/571 [00:16<06:49,  1.34it/s]\u001b[A\n",
            "  4%|▍         | 24/571 [00:17<06:26,  1.41it/s]\u001b[A\n",
            "  4%|▍         | 25/571 [00:18<06:48,  1.34it/s]\u001b[A\n",
            "  5%|▍         | 26/571 [00:18<06:25,  1.41it/s]\u001b[A\n",
            "  5%|▍         | 27/571 [00:19<06:46,  1.34it/s]\u001b[A\n",
            "  5%|▍         | 28/571 [00:20<06:23,  1.42it/s]\u001b[A\n",
            "  5%|▌         | 29/571 [00:21<06:44,  1.34it/s]\u001b[A\n",
            "  5%|▌         | 30/571 [00:21<06:21,  1.42it/s]\u001b[A\n",
            "  5%|▌         | 31/571 [00:22<06:43,  1.34it/s]\u001b[A\n",
            "  6%|▌         | 32/571 [00:23<06:20,  1.42it/s]\u001b[A\n",
            "  6%|▌         | 33/571 [00:24<06:41,  1.34it/s]\u001b[A\n",
            "  6%|▌         | 34/571 [00:24<06:19,  1.42it/s]\u001b[A\n",
            "  6%|▌         | 35/571 [00:25<06:40,  1.34it/s]\u001b[A\n",
            "  6%|▋         | 36/571 [00:26<06:17,  1.42it/s]\u001b[A\n",
            "  6%|▋         | 37/571 [00:26<06:39,  1.34it/s]\u001b[A\n",
            "  7%|▋         | 38/571 [00:27<06:16,  1.42it/s]\u001b[A\n",
            "  7%|▋         | 39/571 [00:28<06:37,  1.34it/s]\u001b[A\n",
            "  7%|▋         | 40/571 [00:29<06:15,  1.41it/s]\u001b[A\n",
            "  7%|▋         | 41/571 [00:29<06:36,  1.34it/s]\u001b[A\n",
            "  7%|▋         | 42/571 [00:30<06:13,  1.41it/s]\u001b[A\n",
            "  8%|▊         | 43/571 [00:31<06:34,  1.34it/s]\u001b[A\n",
            "  8%|▊         | 44/571 [00:31<06:12,  1.41it/s]\u001b[A\n",
            "  8%|▊         | 45/571 [00:32<06:33,  1.34it/s]\u001b[A\n",
            "  8%|▊         | 46/571 [00:33<06:11,  1.41it/s]\u001b[A\n",
            "  8%|▊         | 47/571 [00:34<06:32,  1.34it/s]\u001b[A\n",
            "  8%|▊         | 48/571 [00:34<06:09,  1.41it/s]\u001b[A\n",
            "  9%|▊         | 49/571 [00:35<06:30,  1.34it/s]\u001b[A\n",
            "  9%|▉         | 50/571 [00:36<06:08,  1.41it/s]\u001b[A\n",
            "  9%|▉         | 51/571 [00:37<06:29,  1.34it/s]\u001b[A\n",
            "  9%|▉         | 52/571 [00:37<06:07,  1.41it/s]\u001b[A\n",
            "  9%|▉         | 53/571 [00:38<06:27,  1.34it/s]\u001b[A\n",
            "  9%|▉         | 54/571 [00:39<06:05,  1.41it/s]\u001b[A\n",
            " 10%|▉         | 55/571 [00:40<06:26,  1.34it/s]\u001b[A\n",
            " 10%|▉         | 56/571 [00:40<06:04,  1.41it/s]\u001b[A\n",
            " 10%|▉         | 57/571 [00:41<06:24,  1.34it/s]\u001b[A\n",
            " 10%|█         | 58/571 [00:42<06:02,  1.41it/s]\u001b[A\n",
            " 10%|█         | 59/571 [00:42<06:23,  1.34it/s]\u001b[A\n",
            " 11%|█         | 60/571 [00:43<06:01,  1.41it/s]\u001b[A\n",
            " 11%|█         | 61/571 [00:44<06:21,  1.34it/s]\u001b[A\n",
            " 11%|█         | 62/571 [00:45<05:59,  1.41it/s]\u001b[A\n",
            " 11%|█         | 63/571 [00:45<06:20,  1.34it/s]\u001b[A\n",
            " 11%|█         | 64/571 [00:46<05:58,  1.41it/s]\u001b[A\n",
            " 11%|█▏        | 65/571 [00:47<06:18,  1.34it/s]\u001b[A\n",
            " 12%|█▏        | 66/571 [00:47<05:57,  1.41it/s]\u001b[A\n",
            " 12%|█▏        | 67/571 [00:48<06:17,  1.33it/s]\u001b[A\n",
            " 12%|█▏        | 68/571 [00:49<05:56,  1.41it/s]\u001b[A\n",
            " 12%|█▏        | 69/571 [00:50<06:16,  1.33it/s]\u001b[A\n",
            " 12%|█▏        | 70/571 [00:50<05:54,  1.41it/s]\u001b[A\n",
            " 12%|█▏        | 71/571 [00:51<06:14,  1.34it/s]\u001b[A\n",
            " 13%|█▎        | 72/571 [00:52<05:52,  1.41it/s]\u001b[A\n",
            " 13%|█▎        | 73/571 [00:53<06:13,  1.34it/s]\u001b[A\n",
            " 13%|█▎        | 74/571 [00:53<05:51,  1.41it/s]\u001b[A\n",
            " 13%|█▎        | 75/571 [00:54<06:11,  1.34it/s]\u001b[A\n",
            " 13%|█▎        | 76/571 [00:55<05:50,  1.41it/s]\u001b[A\n",
            " 13%|█▎        | 77/571 [00:56<06:09,  1.34it/s]\u001b[A\n",
            " 14%|█▎        | 78/571 [00:56<05:48,  1.41it/s]\u001b[A\n",
            " 14%|█▍        | 79/571 [00:57<06:08,  1.34it/s]\u001b[A\n",
            " 14%|█▍        | 80/571 [00:58<05:47,  1.41it/s]\u001b[A\n",
            " 14%|█▍        | 81/571 [00:59<06:07,  1.34it/s]\u001b[A\n",
            " 14%|█▍        | 82/571 [00:59<05:46,  1.41it/s]\u001b[A\n",
            " 15%|█▍        | 83/571 [01:00<06:05,  1.34it/s]\u001b[A\n",
            " 15%|█▍        | 84/571 [01:01<05:44,  1.41it/s]\u001b[A\n",
            " 15%|█▍        | 85/571 [01:01<06:03,  1.34it/s]\u001b[A\n",
            " 15%|█▌        | 86/571 [01:02<05:43,  1.41it/s]\u001b[A\n",
            " 15%|█▌        | 87/571 [01:03<06:02,  1.34it/s]\u001b[A\n",
            " 15%|█▌        | 88/571 [01:03<05:41,  1.41it/s]\u001b[A\n",
            " 16%|█▌        | 89/571 [01:04<06:00,  1.34it/s]\u001b[A\n",
            " 16%|█▌        | 90/571 [01:05<05:40,  1.41it/s]\u001b[A\n",
            " 16%|█▌        | 91/571 [01:06<05:59,  1.34it/s]\u001b[A\n",
            " 16%|█▌        | 92/571 [01:06<05:38,  1.41it/s]\u001b[A\n",
            " 16%|█▋        | 93/571 [01:07<05:57,  1.34it/s]\u001b[A\n",
            " 16%|█▋        | 94/571 [01:08<05:37,  1.41it/s]\u001b[A\n",
            " 17%|█▋        | 95/571 [01:09<05:56,  1.33it/s]\u001b[A\n",
            " 17%|█▋        | 96/571 [01:09<05:36,  1.41it/s]\u001b[A\n",
            " 17%|█▋        | 97/571 [01:10<05:55,  1.33it/s]\u001b[A\n",
            " 17%|█▋        | 98/571 [01:11<05:34,  1.41it/s]\u001b[A\n",
            " 17%|█▋        | 99/571 [01:12<05:53,  1.34it/s]\u001b[A\n",
            " 18%|█▊        | 100/571 [01:12<05:33,  1.41it/s]\u001b[A\n",
            " 18%|█▊        | 101/571 [01:13<05:51,  1.34it/s]\u001b[A\n",
            " 18%|█▊        | 102/571 [01:14<05:32,  1.41it/s]\u001b[A\n",
            " 18%|█▊        | 103/571 [01:15<05:50,  1.34it/s]\u001b[A\n",
            " 18%|█▊        | 104/571 [01:15<05:30,  1.41it/s]\u001b[A\n",
            " 18%|█▊        | 105/571 [01:16<05:49,  1.34it/s]\u001b[A\n",
            " 19%|█▊        | 106/571 [01:17<05:29,  1.41it/s]\u001b[A\n",
            " 19%|█▊        | 107/571 [01:17<05:47,  1.34it/s]\u001b[A\n",
            " 19%|█▉        | 108/571 [01:18<05:27,  1.41it/s]\u001b[A\n",
            " 19%|█▉        | 109/571 [01:19<05:45,  1.34it/s]\u001b[A\n",
            " 19%|█▉        | 110/571 [01:20<05:26,  1.41it/s]\u001b[A\n",
            " 19%|█▉        | 111/571 [01:20<05:44,  1.34it/s]\u001b[A\n",
            " 20%|█▉        | 112/571 [01:21<05:24,  1.41it/s]\u001b[A\n",
            " 20%|█▉        | 113/571 [01:22<05:42,  1.34it/s]\u001b[A\n",
            " 20%|█▉        | 114/571 [01:22<05:23,  1.41it/s]\u001b[A\n",
            " 20%|██        | 115/571 [01:23<05:41,  1.34it/s]\u001b[A\n",
            " 20%|██        | 116/571 [01:24<05:21,  1.41it/s]\u001b[A\n",
            " 20%|██        | 117/571 [01:25<05:39,  1.34it/s]\u001b[A\n",
            " 21%|██        | 118/571 [01:25<05:20,  1.41it/s]\u001b[A\n",
            " 21%|██        | 119/571 [01:26<05:38,  1.34it/s]\u001b[A\n",
            " 21%|██        | 120/571 [01:27<05:19,  1.41it/s]\u001b[A\n",
            " 21%|██        | 121/571 [01:28<05:37,  1.34it/s]\u001b[A\n",
            " 21%|██▏       | 122/571 [01:28<05:17,  1.41it/s]\u001b[A\n",
            " 22%|██▏       | 123/571 [01:29<05:35,  1.34it/s]\u001b[A\n",
            " 22%|██▏       | 124/571 [01:30<05:16,  1.41it/s]\u001b[A\n",
            " 22%|██▏       | 125/571 [01:31<05:33,  1.34it/s]\u001b[A\n",
            " 22%|██▏       | 126/571 [01:31<05:14,  1.41it/s]\u001b[A\n",
            " 22%|██▏       | 127/571 [01:32<05:32,  1.34it/s]\u001b[A\n",
            " 22%|██▏       | 128/571 [01:33<05:13,  1.41it/s]\u001b[A\n",
            " 23%|██▎       | 129/571 [01:33<05:31,  1.34it/s]\u001b[A\n",
            " 23%|██▎       | 130/571 [01:34<05:12,  1.41it/s]\u001b[A\n",
            " 23%|██▎       | 131/571 [01:35<05:29,  1.34it/s]\u001b[A\n",
            " 23%|██▎       | 132/571 [01:36<05:10,  1.41it/s]\u001b[A\n",
            " 23%|██▎       | 133/571 [01:36<05:28,  1.34it/s]\u001b[A\n",
            " 23%|██▎       | 134/571 [01:37<05:09,  1.41it/s]\u001b[A\n",
            " 24%|██▎       | 135/571 [01:38<05:26,  1.34it/s]\u001b[A\n",
            " 24%|██▍       | 136/571 [01:38<05:07,  1.41it/s]\u001b[A\n",
            " 24%|██▍       | 137/571 [01:39<05:24,  1.34it/s]\u001b[A\n",
            " 24%|██▍       | 138/571 [01:40<05:06,  1.41it/s]\u001b[A\n",
            " 24%|██▍       | 139/571 [01:41<05:23,  1.34it/s]\u001b[A\n",
            " 25%|██▍       | 140/571 [01:41<05:04,  1.41it/s]\u001b[A\n",
            " 25%|██▍       | 141/571 [01:42<05:22,  1.34it/s]\u001b[A\n",
            " 25%|██▍       | 142/571 [01:43<05:03,  1.41it/s]\u001b[A\n",
            " 25%|██▌       | 143/571 [01:44<05:20,  1.33it/s]\u001b[A\n",
            " 25%|██▌       | 144/571 [01:44<05:02,  1.41it/s]\u001b[A\n",
            " 25%|██▌       | 145/571 [01:45<05:19,  1.33it/s]\u001b[A\n",
            " 26%|██▌       | 146/571 [01:46<05:01,  1.41it/s]\u001b[A\n",
            " 26%|██▌       | 147/571 [01:47<05:17,  1.33it/s]\u001b[A\n",
            " 26%|██▌       | 148/571 [01:47<04:59,  1.41it/s]\u001b[A\n",
            " 26%|██▌       | 149/571 [01:48<05:15,  1.34it/s]\u001b[A\n",
            " 26%|██▋       | 150/571 [01:49<04:58,  1.41it/s]\u001b[A\n",
            " 26%|██▋       | 151/571 [01:49<05:14,  1.33it/s]\u001b[A\n",
            " 27%|██▋       | 152/571 [01:50<04:56,  1.41it/s]\u001b[A\n",
            " 27%|██▋       | 153/571 [01:51<05:13,  1.33it/s]\u001b[A\n",
            " 27%|██▋       | 154/571 [01:52<04:55,  1.41it/s]\u001b[A\n",
            " 27%|██▋       | 155/571 [01:52<05:11,  1.33it/s]\u001b[A\n",
            " 27%|██▋       | 156/571 [01:53<04:53,  1.41it/s]\u001b[A\n",
            " 27%|██▋       | 157/571 [01:54<05:10,  1.33it/s]\u001b[A\n",
            " 28%|██▊       | 158/571 [01:54<04:52,  1.41it/s]\u001b[A\n",
            " 28%|██▊       | 159/571 [01:55<05:08,  1.33it/s]\u001b[A\n",
            " 28%|██▊       | 160/571 [01:56<04:51,  1.41it/s]\u001b[A\n",
            " 28%|██▊       | 161/571 [01:57<05:07,  1.33it/s]\u001b[A\n",
            " 28%|██▊       | 162/571 [01:57<04:49,  1.41it/s]\u001b[A\n",
            " 29%|██▊       | 163/571 [01:58<05:05,  1.33it/s]\u001b[A\n",
            " 29%|██▊       | 164/571 [01:59<04:48,  1.41it/s]\u001b[A\n",
            " 29%|██▉       | 165/571 [02:00<05:04,  1.33it/s]\u001b[A\n",
            " 29%|██▉       | 166/571 [02:00<04:46,  1.41it/s]\u001b[A\n",
            " 29%|██▉       | 167/571 [02:01<05:03,  1.33it/s]\u001b[A\n",
            " 29%|██▉       | 168/571 [02:02<04:45,  1.41it/s]\u001b[A\n",
            " 30%|██▉       | 169/571 [02:03<05:01,  1.33it/s]\u001b[A\n",
            " 30%|██▉       | 170/571 [02:03<04:44,  1.41it/s]\u001b[A\n",
            " 30%|██▉       | 171/571 [02:04<04:59,  1.33it/s]\u001b[A\n",
            " 30%|███       | 172/571 [02:05<04:42,  1.41it/s]\u001b[A\n",
            " 30%|███       | 173/571 [02:06<04:58,  1.33it/s]\u001b[A\n",
            " 30%|███       | 174/571 [02:06<04:41,  1.41it/s]\u001b[A\n",
            " 31%|███       | 175/571 [02:07<04:57,  1.33it/s]\u001b[A\n",
            " 31%|███       | 176/571 [02:08<04:40,  1.41it/s]\u001b[A\n",
            " 31%|███       | 177/571 [02:08<04:55,  1.33it/s]\u001b[A\n",
            " 31%|███       | 178/571 [02:09<04:38,  1.41it/s]\u001b[A\n",
            " 31%|███▏      | 179/571 [02:10<04:53,  1.33it/s]\u001b[A\n",
            " 32%|███▏      | 180/571 [02:11<04:36,  1.41it/s]\u001b[A\n",
            " 32%|███▏      | 181/571 [02:11<04:52,  1.33it/s]\u001b[A\n",
            " 32%|███▏      | 182/571 [02:12<04:35,  1.41it/s]\u001b[A\n",
            " 32%|███▏      | 183/571 [02:13<04:50,  1.33it/s]\u001b[A\n",
            " 32%|███▏      | 184/571 [02:13<04:33,  1.41it/s]\u001b[A\n",
            " 32%|███▏      | 185/571 [02:14<04:49,  1.34it/s]\u001b[A\n",
            " 33%|███▎      | 186/571 [02:15<04:32,  1.41it/s]\u001b[A\n",
            " 33%|███▎      | 187/571 [02:16<04:47,  1.33it/s]\u001b[A\n",
            " 33%|███▎      | 188/571 [02:16<04:31,  1.41it/s]\u001b[A\n",
            " 33%|███▎      | 189/571 [02:17<04:46,  1.33it/s]\u001b[A\n",
            " 33%|███▎      | 190/571 [02:18<04:29,  1.41it/s]\u001b[A\n",
            " 33%|███▎      | 191/571 [02:19<04:44,  1.33it/s]\u001b[A\n",
            " 34%|███▎      | 192/571 [02:19<04:28,  1.41it/s]\u001b[A\n",
            " 34%|███▍      | 193/571 [02:20<04:43,  1.33it/s]\u001b[A\n",
            " 34%|███▍      | 194/571 [02:21<04:26,  1.41it/s]\u001b[A\n",
            " 34%|███▍      | 195/571 [02:22<04:41,  1.33it/s]\u001b[A\n",
            " 34%|███▍      | 196/571 [02:22<04:25,  1.41it/s]\u001b[A\n",
            " 35%|███▍      | 197/571 [02:23<04:40,  1.33it/s]\u001b[A\n",
            " 35%|███▍      | 198/571 [02:24<04:24,  1.41it/s]\u001b[A\n",
            " 35%|███▍      | 199/571 [02:24<04:38,  1.33it/s]\u001b[A\n",
            " 35%|███▌      | 200/571 [02:25<04:22,  1.41it/s]\u001b[A\n",
            " 35%|███▌      | 201/571 [02:26<04:37,  1.33it/s]\u001b[A\n",
            " 35%|███▌      | 202/571 [02:27<04:21,  1.41it/s]\u001b[A\n",
            " 36%|███▌      | 203/571 [02:27<04:36,  1.33it/s]\u001b[A\n",
            " 36%|███▌      | 204/571 [02:28<04:20,  1.41it/s]\u001b[A\n",
            " 36%|███▌      | 205/571 [02:29<04:34,  1.33it/s]\u001b[A\n",
            " 36%|███▌      | 206/571 [02:29<04:18,  1.41it/s]\u001b[A\n",
            " 36%|███▋      | 207/571 [02:30<04:32,  1.33it/s]\u001b[A\n",
            " 36%|███▋      | 208/571 [02:31<04:17,  1.41it/s]\u001b[A\n",
            " 37%|███▋      | 209/571 [02:32<04:31,  1.33it/s]\u001b[A\n",
            " 37%|███▋      | 210/571 [02:32<04:15,  1.41it/s]\u001b[A\n",
            " 37%|███▋      | 211/571 [02:33<04:29,  1.33it/s]\u001b[A\n",
            " 37%|███▋      | 212/571 [02:34<04:14,  1.41it/s]\u001b[A\n",
            " 37%|███▋      | 213/571 [02:35<04:28,  1.33it/s]\u001b[A\n",
            " 37%|███▋      | 214/571 [02:35<04:12,  1.41it/s]\u001b[A\n",
            " 38%|███▊      | 215/571 [02:36<04:26,  1.33it/s]\u001b[A\n",
            " 38%|███▊      | 216/571 [02:37<04:11,  1.41it/s]\u001b[A\n",
            " 38%|███▊      | 217/571 [02:38<04:25,  1.33it/s]\u001b[A\n",
            " 38%|███▊      | 218/571 [02:38<04:09,  1.41it/s]\u001b[A\n",
            " 38%|███▊      | 219/571 [02:39<04:23,  1.33it/s]\u001b[A\n",
            " 39%|███▊      | 220/571 [02:40<04:08,  1.41it/s]\u001b[A\n",
            " 39%|███▊      | 221/571 [02:41<04:22,  1.34it/s]\u001b[A\n",
            " 39%|███▉      | 222/571 [02:41<04:07,  1.41it/s]\u001b[A\n",
            " 39%|███▉      | 223/571 [02:42<04:20,  1.33it/s]\u001b[A\n",
            " 39%|███▉      | 224/571 [02:43<04:05,  1.41it/s]\u001b[A\n",
            " 39%|███▉      | 225/571 [02:43<04:19,  1.34it/s]\u001b[A\n",
            " 40%|███▉      | 226/571 [02:44<04:04,  1.41it/s]\u001b[A\n",
            " 40%|███▉      | 227/571 [02:45<04:17,  1.33it/s]\u001b[A\n",
            " 40%|███▉      | 228/571 [02:46<04:02,  1.41it/s]\u001b[A\n",
            " 40%|████      | 229/571 [02:46<04:16,  1.33it/s]\u001b[A\n",
            " 40%|████      | 230/571 [02:47<04:01,  1.41it/s]\u001b[A\n",
            " 40%|████      | 231/571 [02:48<04:14,  1.33it/s]\u001b[A\n",
            " 41%|████      | 232/571 [02:48<04:00,  1.41it/s]\u001b[A\n",
            " 41%|████      | 233/571 [02:49<04:13,  1.33it/s]\u001b[A\n",
            " 41%|████      | 234/571 [02:50<03:58,  1.41it/s]\u001b[A\n",
            " 41%|████      | 235/571 [02:51<04:11,  1.33it/s]\u001b[A\n",
            " 41%|████▏     | 236/571 [02:51<03:57,  1.41it/s]\u001b[A\n",
            " 42%|████▏     | 237/571 [02:52<04:10,  1.33it/s]\u001b[A\n",
            " 42%|████▏     | 238/571 [02:53<03:55,  1.41it/s]\u001b[A\n",
            " 42%|████▏     | 239/571 [02:54<04:08,  1.33it/s]\u001b[A\n",
            " 42%|████▏     | 240/571 [02:54<03:54,  1.41it/s]\u001b[A\n",
            " 42%|████▏     | 241/571 [02:55<04:07,  1.33it/s]\u001b[A\n",
            " 42%|████▏     | 242/571 [02:56<03:53,  1.41it/s]\u001b[A\n",
            " 43%|████▎     | 243/571 [02:57<04:05,  1.33it/s]\u001b[A\n",
            " 43%|████▎     | 244/571 [02:57<03:51,  1.41it/s]\u001b[A\n",
            " 43%|████▎     | 245/571 [02:58<04:04,  1.33it/s]\u001b[A\n",
            " 43%|████▎     | 246/571 [02:59<03:50,  1.41it/s]\u001b[A\n",
            " 43%|████▎     | 247/571 [02:59<04:02,  1.33it/s]\u001b[A\n",
            " 43%|████▎     | 248/571 [03:00<03:48,  1.41it/s]\u001b[A\n",
            " 44%|████▎     | 249/571 [03:01<04:01,  1.33it/s]\u001b[A\n",
            " 44%|████▍     | 250/571 [03:02<03:47,  1.41it/s]\u001b[A\n",
            " 44%|████▍     | 251/571 [03:02<03:59,  1.33it/s]\u001b[A\n",
            " 44%|████▍     | 252/571 [03:03<03:45,  1.41it/s]\u001b[A\n",
            " 44%|████▍     | 253/571 [03:04<03:58,  1.33it/s]\u001b[A\n",
            " 44%|████▍     | 254/571 [03:04<03:44,  1.41it/s]\u001b[A\n",
            " 45%|████▍     | 255/571 [03:05<03:56,  1.33it/s]\u001b[A\n",
            " 45%|████▍     | 256/571 [03:06<03:43,  1.41it/s]\u001b[A\n",
            " 45%|████▌     | 257/571 [03:07<03:55,  1.33it/s]\u001b[A\n",
            " 45%|████▌     | 258/571 [03:07<03:41,  1.41it/s]\u001b[A\n",
            " 45%|████▌     | 259/571 [03:08<03:53,  1.33it/s]\u001b[A\n",
            " 46%|████▌     | 260/571 [03:09<03:40,  1.41it/s]\u001b[A\n",
            " 46%|████▌     | 261/571 [03:10<03:52,  1.33it/s]\u001b[A\n",
            " 46%|████▌     | 262/571 [03:10<03:38,  1.41it/s]\u001b[A\n",
            " 46%|████▌     | 263/571 [03:11<03:50,  1.33it/s]\u001b[A\n",
            " 46%|████▌     | 264/571 [03:12<03:37,  1.41it/s]\u001b[A\n",
            " 46%|████▋     | 265/571 [03:13<03:49,  1.33it/s]\u001b[A\n",
            " 47%|████▋     | 266/571 [03:13<03:36,  1.41it/s]\u001b[A\n",
            " 47%|████▋     | 267/571 [03:14<03:47,  1.33it/s]\u001b[A\n",
            " 47%|████▋     | 268/571 [03:15<03:34,  1.41it/s]\u001b[A\n",
            " 47%|████▋     | 269/571 [03:16<03:46,  1.33it/s]\u001b[A\n",
            " 47%|████▋     | 270/571 [03:16<03:33,  1.41it/s]\u001b[A\n",
            " 47%|████▋     | 271/571 [03:17<03:44,  1.33it/s]\u001b[A\n",
            " 48%|████▊     | 272/571 [03:18<03:31,  1.41it/s]\u001b[A\n",
            " 48%|████▊     | 273/571 [03:18<03:43,  1.33it/s]\u001b[A\n",
            " 48%|████▊     | 274/571 [03:19<03:30,  1.41it/s]\u001b[A\n",
            " 48%|████▊     | 275/571 [03:20<03:41,  1.33it/s]\u001b[A\n",
            " 48%|████▊     | 276/571 [03:21<03:29,  1.41it/s]\u001b[A\n",
            " 49%|████▊     | 277/571 [03:21<03:40,  1.33it/s]\u001b[A\n",
            " 49%|████▊     | 278/571 [03:22<03:27,  1.41it/s]\u001b[A\n",
            " 49%|████▉     | 279/571 [03:23<03:39,  1.33it/s]\u001b[A\n",
            " 49%|████▉     | 280/571 [03:23<03:26,  1.41it/s]\u001b[A\n",
            " 49%|████▉     | 281/571 [03:24<03:37,  1.33it/s]\u001b[A\n",
            " 49%|████▉     | 282/571 [03:25<03:25,  1.41it/s]\u001b[A\n",
            " 50%|████▉     | 283/571 [03:26<03:36,  1.33it/s]\u001b[A\n",
            " 50%|████▉     | 284/571 [03:26<03:23,  1.41it/s]\u001b[A\n",
            " 50%|████▉     | 285/571 [03:27<03:34,  1.33it/s]\u001b[A\n",
            " 50%|█████     | 286/571 [03:28<03:22,  1.41it/s]\u001b[A\n",
            " 50%|█████     | 287/571 [03:29<03:33,  1.33it/s]\u001b[A\n",
            " 50%|█████     | 288/571 [03:29<03:20,  1.41it/s]\u001b[A\n",
            " 51%|█████     | 289/571 [03:30<03:31,  1.33it/s]\u001b[A\n",
            " 51%|█████     | 290/571 [03:31<03:19,  1.41it/s]\u001b[A\n",
            " 51%|█████     | 291/571 [03:32<03:30,  1.33it/s]\u001b[A\n",
            " 51%|█████     | 292/571 [03:32<03:17,  1.41it/s]\u001b[A\n",
            " 51%|█████▏    | 293/571 [03:33<03:28,  1.33it/s]\u001b[A\n",
            " 51%|█████▏    | 294/571 [03:34<03:16,  1.41it/s]\u001b[A\n",
            " 52%|█████▏    | 295/571 [03:34<03:26,  1.33it/s]\u001b[A\n",
            " 52%|█████▏    | 296/571 [03:35<03:14,  1.41it/s]\u001b[A\n",
            " 52%|█████▏    | 297/571 [03:36<03:25,  1.33it/s]\u001b[A\n",
            " 52%|█████▏    | 298/571 [03:37<03:13,  1.41it/s]\u001b[A\n",
            " 52%|█████▏    | 299/571 [03:37<03:23,  1.33it/s]\u001b[A\n",
            " 53%|█████▎    | 300/571 [03:38<03:12,  1.41it/s]\u001b[A\n",
            " 53%|█████▎    | 301/571 [03:39<03:22,  1.33it/s]\u001b[A\n",
            " 53%|█████▎    | 302/571 [03:39<03:10,  1.41it/s]\u001b[A\n",
            " 53%|█████▎    | 303/571 [03:40<03:20,  1.33it/s]\u001b[A\n",
            " 53%|█████▎    | 304/571 [03:41<03:09,  1.41it/s]\u001b[A\n",
            " 53%|█████▎    | 305/571 [03:42<03:19,  1.33it/s]\u001b[A\n",
            " 54%|█████▎    | 306/571 [03:42<03:07,  1.41it/s]\u001b[A\n",
            " 54%|█████▍    | 307/571 [03:43<03:17,  1.33it/s]\u001b[A\n",
            " 54%|█████▍    | 308/571 [03:44<03:06,  1.41it/s]\u001b[A\n",
            " 54%|█████▍    | 309/571 [03:45<03:16,  1.33it/s]\u001b[A\n",
            " 54%|█████▍    | 310/571 [03:45<03:04,  1.41it/s]\u001b[A\n",
            " 54%|█████▍    | 311/571 [03:46<03:14,  1.33it/s]\u001b[A\n",
            " 55%|█████▍    | 312/571 [03:47<03:03,  1.41it/s]\u001b[A\n",
            " 55%|█████▍    | 313/571 [03:48<03:13,  1.33it/s]\u001b[A\n",
            " 55%|█████▍    | 314/571 [03:48<03:02,  1.41it/s]\u001b[A\n",
            " 55%|█████▌    | 315/571 [03:49<03:12,  1.33it/s]\u001b[A\n",
            " 55%|█████▌    | 316/571 [03:50<03:00,  1.41it/s]\u001b[A\n",
            " 56%|█████▌    | 317/571 [03:51<03:10,  1.33it/s]\u001b[A\n",
            " 56%|█████▌    | 318/571 [03:51<02:59,  1.41it/s]\u001b[A\n",
            " 56%|█████▌    | 319/571 [03:52<03:09,  1.33it/s]\u001b[A\n",
            " 56%|█████▌    | 320/571 [03:53<02:58,  1.41it/s]\u001b[A\n",
            " 56%|█████▌    | 321/571 [03:53<03:07,  1.33it/s]\u001b[A\n",
            " 56%|█████▋    | 322/571 [03:54<02:56,  1.41it/s]\u001b[A\n",
            " 57%|█████▋    | 323/571 [03:55<03:06,  1.33it/s]\u001b[A\n",
            " 57%|█████▋    | 324/571 [03:56<02:55,  1.41it/s]\u001b[A\n",
            " 57%|█████▋    | 325/571 [03:56<03:04,  1.33it/s]\u001b[A\n",
            " 57%|█████▋    | 326/571 [03:57<02:53,  1.41it/s]\u001b[A\n",
            " 57%|█████▋    | 327/571 [03:58<03:03,  1.33it/s]\u001b[A\n",
            " 57%|█████▋    | 328/571 [03:58<02:52,  1.41it/s]\u001b[A\n",
            " 58%|█████▊    | 329/571 [03:59<03:01,  1.33it/s]\u001b[A\n",
            " 58%|█████▊    | 330/571 [04:00<02:51,  1.41it/s]\u001b[A\n",
            " 58%|█████▊    | 331/571 [04:01<03:00,  1.33it/s]\u001b[A\n",
            " 58%|█████▊    | 332/571 [04:01<02:49,  1.41it/s]\u001b[A\n",
            " 58%|█████▊    | 333/571 [04:02<02:58,  1.33it/s]\u001b[A\n",
            " 58%|█████▊    | 334/571 [04:03<02:48,  1.41it/s]\u001b[A\n",
            " 59%|█████▊    | 335/571 [04:04<02:57,  1.33it/s]\u001b[A\n",
            " 59%|█████▉    | 336/571 [04:04<02:46,  1.41it/s]\u001b[A\n",
            " 59%|█████▉    | 337/571 [04:05<02:55,  1.33it/s]\u001b[A\n",
            " 59%|█████▉    | 338/571 [04:06<02:45,  1.41it/s]\u001b[A\n",
            " 59%|█████▉    | 339/571 [04:07<02:54,  1.33it/s]\u001b[A\n",
            " 60%|█████▉    | 340/571 [04:07<02:43,  1.41it/s]\u001b[A\n",
            " 60%|█████▉    | 341/571 [04:08<02:52,  1.33it/s]\u001b[A\n",
            " 60%|█████▉    | 342/571 [04:09<02:42,  1.41it/s]\u001b[A\n",
            " 60%|██████    | 343/571 [04:10<02:51,  1.33it/s]\u001b[A\n",
            " 60%|██████    | 344/571 [04:10<02:40,  1.41it/s]\u001b[A\n",
            " 60%|██████    | 345/571 [04:11<02:49,  1.33it/s]\u001b[A\n",
            " 61%|██████    | 346/571 [04:12<02:39,  1.41it/s]\u001b[A\n",
            " 61%|██████    | 347/571 [04:12<02:48,  1.33it/s]\u001b[A\n",
            " 61%|██████    | 348/571 [04:13<02:38,  1.41it/s]\u001b[A\n",
            " 61%|██████    | 349/571 [04:14<02:46,  1.33it/s]\u001b[A\n",
            " 61%|██████▏   | 350/571 [04:14<02:36,  1.41it/s]\u001b[A\n",
            " 61%|██████▏   | 351/571 [04:15<02:45,  1.33it/s]\u001b[A\n",
            " 62%|██████▏   | 352/571 [04:16<02:35,  1.41it/s]\u001b[A\n",
            " 62%|██████▏   | 353/571 [04:17<02:43,  1.33it/s]\u001b[A\n",
            " 62%|██████▏   | 354/571 [04:17<02:33,  1.41it/s]\u001b[A\n",
            " 62%|██████▏   | 355/571 [04:18<02:41,  1.33it/s]\u001b[A\n",
            " 62%|██████▏   | 356/571 [04:19<02:32,  1.41it/s]\u001b[A\n",
            " 63%|██████▎   | 357/571 [04:20<02:40,  1.33it/s]\u001b[A\n",
            " 63%|██████▎   | 358/571 [04:20<02:30,  1.41it/s]\u001b[A\n",
            " 63%|██████▎   | 359/571 [04:21<02:39,  1.33it/s]\u001b[A\n",
            " 63%|██████▎   | 360/571 [04:22<02:29,  1.41it/s]\u001b[A\n",
            " 63%|██████▎   | 361/571 [04:23<02:37,  1.33it/s]\u001b[A\n",
            " 63%|██████▎   | 362/571 [04:23<02:28,  1.41it/s]\u001b[A\n",
            " 64%|██████▎   | 363/571 [04:24<02:36,  1.33it/s]\u001b[A\n",
            " 64%|██████▎   | 364/571 [04:25<02:26,  1.41it/s]\u001b[A\n",
            " 64%|██████▍   | 365/571 [04:26<02:34,  1.33it/s]\u001b[A\n",
            " 64%|██████▍   | 366/571 [04:26<02:25,  1.41it/s]\u001b[A\n",
            " 64%|██████▍   | 367/571 [04:27<02:32,  1.33it/s]\u001b[A\n",
            " 64%|██████▍   | 368/571 [04:28<02:23,  1.41it/s]\u001b[A\n",
            " 65%|██████▍   | 369/571 [04:28<02:31,  1.33it/s]\u001b[A\n",
            " 65%|██████▍   | 370/571 [04:29<02:22,  1.41it/s]\u001b[A\n",
            " 65%|██████▍   | 371/571 [04:30<02:30,  1.33it/s]\u001b[A\n",
            " 65%|██████▌   | 372/571 [04:31<02:21,  1.41it/s]\u001b[A\n",
            " 65%|██████▌   | 373/571 [04:31<02:28,  1.33it/s]\u001b[A\n",
            " 65%|██████▌   | 374/571 [04:32<02:19,  1.41it/s]\u001b[A\n",
            " 66%|██████▌   | 375/571 [04:33<02:26,  1.33it/s]\u001b[A\n",
            " 66%|██████▌   | 376/571 [04:33<02:18,  1.41it/s]\u001b[A\n",
            " 66%|██████▌   | 377/571 [04:34<02:25,  1.33it/s]\u001b[A\n",
            " 66%|██████▌   | 378/571 [04:35<02:16,  1.41it/s]\u001b[A\n",
            " 66%|██████▋   | 379/571 [04:36<02:23,  1.34it/s]\u001b[A\n",
            " 67%|██████▋   | 380/571 [04:36<02:15,  1.41it/s]\u001b[A\n",
            " 67%|██████▋   | 381/571 [04:37<02:22,  1.34it/s]\u001b[A\n",
            " 67%|██████▋   | 382/571 [04:38<02:13,  1.41it/s]\u001b[A\n",
            " 67%|██████▋   | 383/571 [04:39<02:20,  1.34it/s]\u001b[A\n",
            " 67%|██████▋   | 384/571 [04:39<02:12,  1.41it/s]\u001b[A\n",
            " 67%|██████▋   | 385/571 [04:40<02:19,  1.34it/s]\u001b[A\n",
            " 68%|██████▊   | 386/571 [04:41<02:10,  1.41it/s]\u001b[A\n",
            " 68%|██████▊   | 387/571 [04:42<02:17,  1.33it/s]\u001b[A\n",
            " 68%|██████▊   | 388/571 [04:42<02:09,  1.41it/s]\u001b[A\n",
            " 68%|██████▊   | 389/571 [04:43<02:16,  1.34it/s]\u001b[A\n",
            " 68%|██████▊   | 390/571 [04:44<02:08,  1.41it/s]\u001b[A\n",
            " 68%|██████▊   | 391/571 [04:44<02:14,  1.33it/s]\u001b[A\n",
            " 69%|██████▊   | 392/571 [04:45<02:06,  1.41it/s]\u001b[A\n",
            " 69%|██████▉   | 393/571 [04:46<02:13,  1.33it/s]\u001b[A\n",
            " 69%|██████▉   | 394/571 [04:47<02:05,  1.41it/s]\u001b[A\n",
            " 69%|██████▉   | 395/571 [04:47<02:11,  1.34it/s]\u001b[A\n",
            " 69%|██████▉   | 396/571 [04:48<02:03,  1.41it/s]\u001b[A\n",
            " 70%|██████▉   | 397/571 [04:49<02:10,  1.33it/s]\u001b[A\n",
            " 70%|██████▉   | 398/571 [04:49<02:02,  1.41it/s]\u001b[A\n",
            " 70%|██████▉   | 399/571 [04:50<02:08,  1.33it/s]\u001b[A\n",
            " 70%|███████   | 400/571 [04:51<02:01,  1.41it/s]\u001b[A\n",
            " 70%|███████   | 401/571 [04:52<02:07,  1.33it/s]\u001b[A\n",
            " 70%|███████   | 402/571 [04:52<01:59,  1.41it/s]\u001b[A\n",
            " 71%|███████   | 403/571 [04:53<02:05,  1.33it/s]\u001b[A\n",
            " 71%|███████   | 404/571 [04:54<01:58,  1.41it/s]\u001b[A\n",
            " 71%|███████   | 405/571 [04:55<02:04,  1.34it/s]\u001b[A\n",
            " 71%|███████   | 406/571 [04:55<01:56,  1.41it/s]\u001b[A\n",
            " 71%|███████▏  | 407/571 [04:56<02:02,  1.34it/s]\u001b[A\n",
            " 71%|███████▏  | 408/571 [04:57<01:55,  1.41it/s]\u001b[A\n",
            " 72%|███████▏  | 409/571 [04:58<02:01,  1.33it/s]\u001b[A\n",
            " 72%|███████▏  | 410/571 [04:58<01:54,  1.41it/s]\u001b[A\n",
            " 72%|███████▏  | 411/571 [04:59<01:59,  1.33it/s]\u001b[A\n",
            " 72%|███████▏  | 412/571 [05:00<01:52,  1.41it/s]\u001b[A\n",
            " 72%|███████▏  | 413/571 [05:01<01:58,  1.33it/s]\u001b[A\n",
            " 73%|███████▎  | 414/571 [05:01<01:51,  1.41it/s]\u001b[A\n",
            " 73%|███████▎  | 415/571 [05:02<01:56,  1.33it/s]\u001b[A\n",
            " 73%|███████▎  | 416/571 [05:03<01:49,  1.41it/s]\u001b[A\n",
            " 73%|███████▎  | 417/571 [05:03<01:55,  1.33it/s]\u001b[A\n",
            " 73%|███████▎  | 418/571 [05:04<01:48,  1.41it/s]\u001b[A\n",
            " 73%|███████▎  | 419/571 [05:05<01:53,  1.33it/s]\u001b[A\n",
            " 74%|███████▎  | 420/571 [05:06<01:46,  1.41it/s]\u001b[A\n",
            " 74%|███████▎  | 421/571 [05:06<01:52,  1.33it/s]\u001b[A\n",
            " 74%|███████▍  | 422/571 [05:07<01:45,  1.41it/s]\u001b[A\n",
            " 74%|███████▍  | 423/571 [05:08<01:50,  1.33it/s]\u001b[A\n",
            " 74%|███████▍  | 424/571 [05:08<01:44,  1.41it/s]\u001b[A\n",
            " 74%|███████▍  | 425/571 [05:09<01:49,  1.33it/s]\u001b[A\n",
            " 75%|███████▍  | 426/571 [05:10<01:42,  1.41it/s]\u001b[A\n",
            " 75%|███████▍  | 427/571 [05:11<01:48,  1.33it/s]\u001b[A\n",
            " 75%|███████▍  | 428/571 [05:11<01:41,  1.41it/s]\u001b[A\n",
            " 75%|███████▌  | 429/571 [05:12<01:46,  1.33it/s]\u001b[A\n",
            " 75%|███████▌  | 430/571 [05:13<01:39,  1.41it/s]\u001b[A\n",
            " 75%|███████▌  | 431/571 [05:14<01:44,  1.33it/s]\u001b[A\n",
            " 76%|███████▌  | 432/571 [05:14<01:38,  1.41it/s]\u001b[A\n",
            " 76%|███████▌  | 433/571 [05:15<01:43,  1.33it/s]\u001b[A\n",
            " 76%|███████▌  | 434/571 [05:16<01:37,  1.41it/s]\u001b[A\n",
            " 76%|███████▌  | 435/571 [05:17<01:42,  1.33it/s]\u001b[A\n",
            " 76%|███████▋  | 436/571 [05:17<01:35,  1.41it/s]\u001b[A\n",
            " 77%|███████▋  | 437/571 [05:18<01:40,  1.33it/s]\u001b[A\n",
            " 77%|███████▋  | 438/571 [05:19<01:34,  1.41it/s]\u001b[A\n",
            " 77%|███████▋  | 439/571 [05:19<01:39,  1.33it/s]\u001b[A\n",
            " 77%|███████▋  | 440/571 [05:20<01:32,  1.41it/s]\u001b[A\n",
            " 77%|███████▋  | 441/571 [05:21<01:37,  1.33it/s]\u001b[A\n",
            " 77%|███████▋  | 442/571 [05:22<01:31,  1.41it/s]\u001b[A\n",
            " 78%|███████▊  | 443/571 [05:22<01:36,  1.33it/s]\u001b[A\n",
            " 78%|███████▊  | 444/571 [05:23<01:30,  1.41it/s]\u001b[A\n",
            " 78%|███████▊  | 445/571 [05:24<01:34,  1.33it/s]\u001b[A\n",
            " 78%|███████▊  | 446/571 [05:24<01:28,  1.41it/s]\u001b[A\n",
            " 78%|███████▊  | 447/571 [05:25<01:33,  1.33it/s]\u001b[A\n",
            " 78%|███████▊  | 448/571 [05:26<01:27,  1.41it/s]\u001b[A\n",
            " 79%|███████▊  | 449/571 [05:27<01:31,  1.33it/s]\u001b[A\n",
            " 79%|███████▉  | 450/571 [05:27<01:25,  1.41it/s]\u001b[A\n",
            " 79%|███████▉  | 451/571 [05:28<01:30,  1.33it/s]\u001b[A\n",
            " 79%|███████▉  | 452/571 [05:29<01:24,  1.41it/s]\u001b[A\n",
            " 79%|███████▉  | 453/571 [05:30<01:28,  1.33it/s]\u001b[A\n",
            " 80%|███████▉  | 454/571 [05:30<01:22,  1.41it/s]\u001b[A\n",
            " 80%|███████▉  | 455/571 [05:31<01:27,  1.33it/s]\u001b[A\n",
            " 80%|███████▉  | 456/571 [05:32<01:21,  1.41it/s]\u001b[A\n",
            " 80%|████████  | 457/571 [05:33<01:25,  1.33it/s]\u001b[A\n",
            " 80%|████████  | 458/571 [05:33<01:20,  1.41it/s]\u001b[A\n",
            " 80%|████████  | 459/571 [05:34<01:24,  1.33it/s]\u001b[A\n",
            " 81%|████████  | 460/571 [05:35<01:18,  1.41it/s]\u001b[A\n",
            " 81%|████████  | 461/571 [05:36<01:22,  1.33it/s]\u001b[A\n",
            " 81%|████████  | 462/571 [05:36<01:17,  1.41it/s]\u001b[A\n",
            " 81%|████████  | 463/571 [05:37<01:21,  1.33it/s]\u001b[A\n",
            " 81%|████████▏ | 464/571 [05:38<01:15,  1.41it/s]\u001b[A\n",
            " 81%|████████▏ | 465/571 [05:38<01:19,  1.33it/s]\u001b[A\n",
            " 82%|████████▏ | 466/571 [05:39<01:14,  1.41it/s]\u001b[A\n",
            " 82%|████████▏ | 467/571 [05:40<01:18,  1.33it/s]\u001b[A\n",
            " 82%|████████▏ | 468/571 [05:41<01:13,  1.41it/s]\u001b[A\n",
            " 82%|████████▏ | 469/571 [05:41<01:16,  1.33it/s]\u001b[A\n",
            " 82%|████████▏ | 470/571 [05:42<01:11,  1.41it/s]\u001b[A\n",
            " 82%|████████▏ | 471/571 [05:43<01:15,  1.33it/s]\u001b[A\n",
            " 83%|████████▎ | 472/571 [05:43<01:10,  1.41it/s]\u001b[A\n",
            " 83%|████████▎ | 473/571 [05:44<01:13,  1.33it/s]\u001b[A\n",
            " 83%|████████▎ | 474/571 [05:45<01:08,  1.41it/s]\u001b[A\n",
            " 83%|████████▎ | 475/571 [05:46<01:12,  1.33it/s]\u001b[A\n",
            " 83%|████████▎ | 476/571 [05:46<01:07,  1.41it/s]\u001b[A\n",
            " 84%|████████▎ | 477/571 [05:47<01:10,  1.33it/s]\u001b[A\n",
            " 84%|████████▎ | 478/571 [05:48<01:05,  1.41it/s]\u001b[A\n",
            " 84%|████████▍ | 479/571 [05:49<01:09,  1.33it/s]\u001b[A\n",
            " 84%|████████▍ | 480/571 [05:49<01:04,  1.41it/s]\u001b[A\n",
            " 84%|████████▍ | 481/571 [05:50<01:07,  1.33it/s]\u001b[A\n",
            " 84%|████████▍ | 482/571 [05:51<01:03,  1.41it/s]\u001b[A\n",
            " 85%|████████▍ | 483/571 [05:52<01:06,  1.33it/s]\u001b[A\n",
            " 85%|████████▍ | 484/571 [05:52<01:01,  1.41it/s]\u001b[A\n",
            " 85%|████████▍ | 485/571 [05:53<01:04,  1.33it/s]\u001b[A\n",
            " 85%|████████▌ | 486/571 [05:54<01:00,  1.41it/s]\u001b[A\n",
            " 85%|████████▌ | 487/571 [05:55<01:03,  1.33it/s]\u001b[A\n",
            " 85%|████████▌ | 488/571 [05:55<00:58,  1.41it/s]\u001b[A\n",
            " 86%|████████▌ | 489/571 [05:56<01:01,  1.33it/s]\u001b[A\n",
            " 86%|████████▌ | 490/571 [05:57<00:57,  1.41it/s]\u001b[A\n",
            " 86%|████████▌ | 491/571 [05:57<01:00,  1.33it/s]\u001b[A\n",
            " 86%|████████▌ | 492/571 [05:58<00:55,  1.41it/s]\u001b[A\n",
            " 86%|████████▋ | 493/571 [05:59<00:58,  1.33it/s]\u001b[A\n",
            " 87%|████████▋ | 494/571 [06:00<00:54,  1.41it/s]\u001b[A\n",
            " 87%|████████▋ | 495/571 [06:00<00:57,  1.33it/s]\u001b[A\n",
            " 87%|████████▋ | 496/571 [06:01<00:53,  1.41it/s]\u001b[A\n",
            " 87%|████████▋ | 497/571 [06:02<00:55,  1.33it/s]\u001b[A\n",
            " 87%|████████▋ | 498/571 [06:02<00:51,  1.41it/s]\u001b[A\n",
            " 87%|████████▋ | 499/571 [06:03<00:54,  1.33it/s]\u001b[A\n",
            " 88%|████████▊ | 500/571 [06:04<00:50,  1.41it/s]\u001b[A\n",
            " 88%|████████▊ | 501/571 [06:05<00:52,  1.33it/s]\u001b[A\n",
            " 88%|████████▊ | 502/571 [06:05<00:48,  1.41it/s]\u001b[A\n",
            " 88%|████████▊ | 503/571 [06:06<00:51,  1.33it/s]\u001b[A\n",
            " 88%|████████▊ | 504/571 [06:07<00:47,  1.41it/s]\u001b[A\n",
            " 88%|████████▊ | 505/571 [06:08<00:49,  1.33it/s]\u001b[A\n",
            " 89%|████████▊ | 506/571 [06:08<00:46,  1.41it/s]\u001b[A\n",
            " 89%|████████▉ | 507/571 [06:09<00:47,  1.33it/s]\u001b[A\n",
            " 89%|████████▉ | 508/571 [06:10<00:44,  1.41it/s]\u001b[A\n",
            " 89%|████████▉ | 509/571 [06:11<00:46,  1.33it/s]\u001b[A\n",
            " 89%|████████▉ | 510/571 [06:11<00:43,  1.41it/s]\u001b[A\n",
            " 89%|████████▉ | 511/571 [06:12<00:45,  1.33it/s]\u001b[A\n",
            " 90%|████████▉ | 512/571 [06:13<00:41,  1.41it/s]\u001b[A\n",
            " 90%|████████▉ | 513/571 [06:13<00:43,  1.33it/s]\u001b[A\n",
            " 90%|█████████ | 514/571 [06:14<00:40,  1.41it/s]\u001b[A\n",
            " 90%|█████████ | 515/571 [06:15<00:41,  1.33it/s]\u001b[A\n",
            " 90%|█████████ | 516/571 [06:16<00:38,  1.41it/s]\u001b[A\n",
            " 91%|█████████ | 517/571 [06:16<00:40,  1.33it/s]\u001b[A\n",
            " 91%|█████████ | 518/571 [06:17<00:37,  1.41it/s]\u001b[A\n",
            " 91%|█████████ | 519/571 [06:18<00:39,  1.33it/s]\u001b[A\n",
            " 91%|█████████ | 520/571 [06:18<00:36,  1.41it/s]\u001b[A\n",
            " 91%|█████████ | 521/571 [06:19<00:37,  1.33it/s]\u001b[A\n",
            " 91%|█████████▏| 522/571 [06:20<00:34,  1.41it/s]\u001b[A\n",
            " 92%|█████████▏| 523/571 [06:21<00:35,  1.33it/s]\u001b[A\n",
            " 92%|█████████▏| 524/571 [06:21<00:33,  1.41it/s]\u001b[A\n",
            " 92%|█████████▏| 525/571 [06:22<00:34,  1.33it/s]\u001b[A\n",
            " 92%|█████████▏| 526/571 [06:23<00:31,  1.41it/s]\u001b[A\n",
            " 92%|█████████▏| 527/571 [06:24<00:33,  1.33it/s]\u001b[A\n",
            " 92%|█████████▏| 528/571 [06:24<00:30,  1.41it/s]\u001b[A\n",
            " 93%|█████████▎| 529/571 [06:25<00:31,  1.33it/s]\u001b[A\n",
            " 93%|█████████▎| 530/571 [06:26<00:29,  1.41it/s]\u001b[A\n",
            " 93%|█████████▎| 531/571 [06:27<00:30,  1.33it/s]\u001b[A\n",
            " 93%|█████████▎| 532/571 [06:27<00:27,  1.41it/s]\u001b[A\n",
            " 93%|█████████▎| 533/571 [06:28<00:28,  1.33it/s]\u001b[A\n",
            " 94%|█████████▎| 534/571 [06:29<00:26,  1.41it/s]\u001b[A\n",
            " 94%|█████████▎| 535/571 [06:30<00:27,  1.33it/s]\u001b[A\n",
            " 94%|█████████▍| 536/571 [06:30<00:24,  1.41it/s]\u001b[A\n",
            " 94%|█████████▍| 537/571 [06:31<00:25,  1.33it/s]\u001b[A\n",
            " 94%|█████████▍| 538/571 [06:32<00:23,  1.41it/s]\u001b[A\n",
            " 94%|█████████▍| 539/571 [06:32<00:24,  1.33it/s]\u001b[A\n",
            " 95%|█████████▍| 540/571 [06:33<00:21,  1.41it/s]\u001b[A\n",
            " 95%|█████████▍| 541/571 [06:34<00:22,  1.33it/s]\u001b[A\n",
            " 95%|█████████▍| 542/571 [06:35<00:20,  1.41it/s]\u001b[A\n",
            " 95%|█████████▌| 543/571 [06:35<00:21,  1.33it/s]\u001b[A\n",
            " 95%|█████████▌| 544/571 [06:36<00:19,  1.41it/s]\u001b[A\n",
            " 95%|█████████▌| 545/571 [06:37<00:19,  1.33it/s]\u001b[A\n",
            " 96%|█████████▌| 546/571 [06:37<00:17,  1.41it/s]\u001b[A\n",
            " 96%|█████████▌| 547/571 [06:38<00:17,  1.33it/s]\u001b[A\n",
            " 96%|█████████▌| 548/571 [06:39<00:16,  1.41it/s]\u001b[A\n",
            " 96%|█████████▌| 549/571 [06:40<00:16,  1.33it/s]\u001b[A\n",
            " 96%|█████████▋| 550/571 [06:40<00:14,  1.41it/s]\u001b[A\n",
            " 96%|█████████▋| 551/571 [06:41<00:14,  1.33it/s]\u001b[A\n",
            " 97%|█████████▋| 552/571 [06:42<00:13,  1.41it/s]\u001b[A\n",
            " 97%|█████████▋| 553/571 [06:43<00:13,  1.34it/s]\u001b[A\n",
            " 97%|█████████▋| 554/571 [06:43<00:12,  1.41it/s]\u001b[A\n",
            " 97%|█████████▋| 555/571 [06:44<00:11,  1.33it/s]\u001b[A\n",
            " 97%|█████████▋| 556/571 [06:45<00:10,  1.41it/s]\u001b[A\n",
            " 98%|█████████▊| 557/571 [06:46<00:10,  1.33it/s]\u001b[A\n",
            " 98%|█████████▊| 558/571 [06:46<00:09,  1.41it/s]\u001b[A\n",
            " 98%|█████████▊| 559/571 [06:47<00:08,  1.33it/s]\u001b[A\n",
            " 98%|█████████▊| 560/571 [06:48<00:07,  1.41it/s]\u001b[A\n",
            " 98%|█████████▊| 561/571 [06:49<00:07,  1.33it/s]\u001b[A\n",
            " 98%|█████████▊| 562/571 [06:49<00:06,  1.41it/s]\u001b[A\n",
            " 99%|█████████▊| 563/571 [06:50<00:05,  1.33it/s]\u001b[A\n",
            " 99%|█████████▉| 564/571 [06:51<00:04,  1.41it/s]\u001b[A\n",
            " 99%|█████████▉| 565/571 [06:51<00:04,  1.33it/s]\u001b[A\n",
            " 99%|█████████▉| 566/571 [06:52<00:03,  1.41it/s]\u001b[A\n",
            " 99%|█████████▉| 567/571 [06:53<00:03,  1.33it/s]\u001b[A\n",
            " 99%|█████████▉| 568/571 [06:53<00:02,  1.41it/s]\u001b[A\n",
            "100%|█████████▉| 569/571 [06:54<00:01,  1.33it/s]\u001b[A\n",
            "100%|█████████▉| 570/571 [06:55<00:00,  1.41it/s]\u001b[A\n",
            "100%|██████████| 571/571 [06:56<00:00,  1.37it/s]\u001b[A\n",
            "\n",
            "  0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
            "doing validation:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
            "doing validation:   1%|          | 1/94 [00:00<00:18,  5.01it/s]\u001b[A\n",
            "doing validation:   1%|          | 1/94 [00:00<00:18,  5.01it/s]\u001b[A\n",
            "doing validation:   2%|▏         | 2/94 [00:00<00:16,  5.63it/s]\u001b[A\n",
            "doing validation:   2%|▏         | 2/94 [00:00<00:16,  5.63it/s]\u001b[A\n",
            "doing validation:   3%|▎         | 3/94 [00:00<00:15,  5.86it/s]\u001b[A\n",
            "doing validation:   3%|▎         | 3/94 [00:00<00:15,  5.86it/s]\u001b[A\n",
            "doing validation:   4%|▍         | 4/94 [00:00<00:15,  5.96it/s]\u001b[A\n",
            "doing validation:   4%|▍         | 4/94 [00:00<00:15,  5.96it/s]\u001b[A\n",
            "doing validation:   5%|▌         | 5/94 [00:00<00:14,  6.03it/s]\u001b[A\n",
            "doing validation:   5%|▌         | 5/94 [00:00<00:14,  6.03it/s]\u001b[A\n",
            "doing validation:   6%|▋         | 6/94 [00:01<00:14,  6.09it/s]\u001b[A\n",
            "doing validation:   6%|▋         | 6/94 [00:01<00:14,  6.09it/s]\u001b[A\n",
            "doing validation:   7%|▋         | 7/94 [00:01<00:14,  6.11it/s]\u001b[A\n",
            "doing validation:   7%|▋         | 7/94 [00:01<00:14,  6.11it/s]\u001b[A\n",
            "doing validation:   9%|▊         | 8/94 [00:01<00:14,  6.11it/s]\u001b[A\n",
            "doing validation:   9%|▊         | 8/94 [00:01<00:14,  6.11it/s]\u001b[A\n",
            "doing validation:  10%|▉         | 9/94 [00:01<00:13,  6.12it/s]\u001b[A\n",
            "doing validation:  10%|▉         | 9/94 [00:01<00:13,  6.12it/s]\u001b[A\n",
            "doing validation:  11%|█         | 10/94 [00:01<00:13,  6.16it/s]\u001b[A\n",
            "doing validation:  11%|█         | 10/94 [00:01<00:13,  6.16it/s]\u001b[A\n",
            "doing validation:  12%|█▏        | 11/94 [00:01<00:13,  6.18it/s]\u001b[A\n",
            "doing validation:  12%|█▏        | 11/94 [00:01<00:13,  6.18it/s]\u001b[A\n",
            "doing validation:  13%|█▎        | 12/94 [00:01<00:13,  6.19it/s]\u001b[A\n",
            "doing validation:  13%|█▎        | 12/94 [00:01<00:13,  6.19it/s]\u001b[A\n",
            "doing validation:  14%|█▍        | 13/94 [00:02<00:13,  6.20it/s]\u001b[A\n",
            "doing validation:  14%|█▍        | 13/94 [00:02<00:13,  6.20it/s]\u001b[A\n",
            "doing validation:  15%|█▍        | 14/94 [00:02<00:12,  6.21it/s]\u001b[A\n",
            "doing validation:  15%|█▍        | 14/94 [00:02<00:12,  6.21it/s]\u001b[A\n",
            "doing validation:  16%|█▌        | 15/94 [00:02<00:12,  6.21it/s]\u001b[A\n",
            "doing validation:  16%|█▌        | 15/94 [00:02<00:12,  6.21it/s]\u001b[A\n",
            "doing validation:  17%|█▋        | 16/94 [00:02<00:12,  6.22it/s]\u001b[A\n",
            "doing validation:  17%|█▋        | 16/94 [00:02<00:12,  6.22it/s]\u001b[A\n",
            "doing validation:  18%|█▊        | 17/94 [00:02<00:12,  6.22it/s]\u001b[A\n",
            "doing validation:  18%|█▊        | 17/94 [00:02<00:12,  6.22it/s]\u001b[A\n",
            "doing validation:  19%|█▉        | 18/94 [00:02<00:12,  6.23it/s]\u001b[A\n",
            "doing validation:  19%|█▉        | 18/94 [00:02<00:12,  6.23it/s]\u001b[A\n",
            "doing validation:  20%|██        | 19/94 [00:03<00:12,  6.22it/s]\u001b[A\n",
            "doing validation:  20%|██        | 19/94 [00:03<00:12,  6.22it/s]\u001b[A\n",
            "doing validation:  21%|██▏       | 20/94 [00:03<00:11,  6.24it/s]\u001b[A\n",
            "doing validation:  21%|██▏       | 20/94 [00:03<00:11,  6.24it/s]\u001b[A\n",
            "doing validation:  22%|██▏       | 21/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  22%|██▏       | 21/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  23%|██▎       | 22/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  23%|██▎       | 22/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  24%|██▍       | 23/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  24%|██▍       | 23/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  26%|██▌       | 24/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  26%|██▌       | 24/94 [00:03<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  27%|██▋       | 25/94 [00:04<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  27%|██▋       | 25/94 [00:04<00:11,  6.22it/s]\u001b[A\n",
            "doing validation:  28%|██▊       | 26/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  28%|██▊       | 26/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  29%|██▊       | 27/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  29%|██▊       | 27/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  30%|██▉       | 28/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  30%|██▉       | 28/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  31%|███       | 29/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  31%|███       | 29/94 [00:04<00:10,  6.22it/s]\u001b[A\n",
            "doing validation:  32%|███▏      | 30/94 [00:04<00:10,  6.23it/s]\u001b[A\n",
            "doing validation:  32%|███▏      | 30/94 [00:04<00:10,  6.23it/s]\u001b[A\n",
            "doing validation:  33%|███▎      | 31/94 [00:05<00:10,  6.23it/s]\u001b[A\n",
            "doing validation:  33%|███▎      | 31/94 [00:05<00:10,  6.23it/s]\u001b[A\n",
            "doing validation:  34%|███▍      | 32/94 [00:05<00:09,  6.23it/s]\u001b[A\n",
            "doing validation:  34%|███▍      | 32/94 [00:05<00:09,  6.23it/s]\u001b[A\n",
            "doing validation:  35%|███▌      | 33/94 [00:05<00:09,  6.21it/s]\u001b[A\n",
            "doing validation:  35%|███▌      | 33/94 [00:05<00:09,  6.21it/s]\u001b[A\n",
            "doing validation:  36%|███▌      | 34/94 [00:05<00:09,  6.22it/s]\u001b[A\n",
            "doing validation:  36%|███▌      | 34/94 [00:05<00:09,  6.22it/s]\u001b[A\n",
            "doing validation:  37%|███▋      | 35/94 [00:05<00:09,  6.22it/s]\u001b[A\n",
            "doing validation:  37%|███▋      | 35/94 [00:05<00:09,  6.22it/s]\u001b[A\n",
            "doing validation:  38%|███▊      | 36/94 [00:05<00:09,  6.21it/s]\u001b[A\n",
            "doing validation:  38%|███▊      | 36/94 [00:05<00:09,  6.21it/s]\u001b[A\n",
            "doing validation:  39%|███▉      | 37/94 [00:05<00:09,  6.22it/s]\u001b[A\n",
            "doing validation:  39%|███▉      | 37/94 [00:06<00:09,  6.22it/s]\u001b[A\n",
            "doing validation:  40%|████      | 38/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  40%|████      | 38/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  41%|████▏     | 39/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  41%|████▏     | 39/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  43%|████▎     | 40/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  43%|████▎     | 40/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  44%|████▎     | 41/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  44%|████▎     | 41/94 [00:06<00:08,  6.23it/s]\u001b[A\n",
            "doing validation:  45%|████▍     | 42/94 [00:06<00:08,  6.24it/s]\u001b[A\n",
            "doing validation:  45%|████▍     | 42/94 [00:06<00:08,  6.24it/s]\u001b[A\n",
            "doing validation:  46%|████▌     | 43/94 [00:06<00:08,  6.24it/s]\u001b[A\n",
            "doing validation:  46%|████▌     | 43/94 [00:06<00:08,  6.24it/s]\u001b[A\n",
            "doing validation:  47%|████▋     | 44/94 [00:07<00:08,  6.24it/s]\u001b[A\n",
            "doing validation:  47%|████▋     | 44/94 [00:07<00:08,  6.24it/s]\u001b[A\n",
            "doing validation:  48%|████▊     | 45/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  48%|████▊     | 45/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  49%|████▉     | 46/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  49%|████▉     | 46/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  50%|█████     | 47/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  50%|█████     | 47/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  51%|█████     | 48/94 [00:07<00:07,  6.23it/s]\u001b[A\n",
            "doing validation:  51%|█████     | 48/94 [00:07<00:07,  6.23it/s]\u001b[A\n",
            "doing validation:  52%|█████▏    | 49/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  52%|█████▏    | 49/94 [00:07<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  53%|█████▎    | 50/94 [00:08<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  53%|█████▎    | 50/94 [00:08<00:07,  6.24it/s]\u001b[A\n",
            "doing validation:  54%|█████▍    | 51/94 [00:08<00:06,  6.21it/s]\u001b[A\n",
            "doing validation:  54%|█████▍    | 51/94 [00:08<00:06,  6.21it/s]\u001b[A\n",
            "doing validation:  55%|█████▌    | 52/94 [00:08<00:06,  6.19it/s]\u001b[A\n",
            "doing validation:  55%|█████▌    | 52/94 [00:08<00:06,  6.19it/s]\u001b[A\n",
            "doing validation:  56%|█████▋    | 53/94 [00:08<00:06,  6.18it/s]\u001b[A\n",
            "doing validation:  56%|█████▋    | 53/94 [00:08<00:06,  6.18it/s]\u001b[A\n",
            "doing validation:  57%|█████▋    | 54/94 [00:08<00:06,  6.18it/s]\u001b[A\n",
            "doing validation:  57%|█████▋    | 54/94 [00:08<00:06,  6.18it/s]\u001b[A\n",
            "doing validation:  59%|█████▊    | 55/94 [00:08<00:06,  6.20it/s]\u001b[A\n",
            "doing validation:  59%|█████▊    | 55/94 [00:08<00:06,  6.20it/s]\u001b[A\n",
            "doing validation:  60%|█████▉    | 56/94 [00:09<00:06,  6.19it/s]\u001b[A\n",
            "doing validation:  60%|█████▉    | 56/94 [00:09<00:06,  6.19it/s]\u001b[A\n",
            "doing validation:  61%|██████    | 57/94 [00:09<00:05,  6.20it/s]\u001b[A\n",
            "doing validation:  61%|██████    | 57/94 [00:09<00:05,  6.20it/s]\u001b[A\n",
            "doing validation:  62%|██████▏   | 58/94 [00:09<00:05,  6.21it/s]\u001b[A\n",
            "doing validation:  62%|██████▏   | 58/94 [00:09<00:05,  6.21it/s]\u001b[A\n",
            "doing validation:  63%|██████▎   | 59/94 [00:09<00:05,  6.21it/s]\u001b[A\n",
            "doing validation:  63%|██████▎   | 59/94 [00:09<00:05,  6.21it/s]\u001b[A\n",
            "doing validation:  64%|██████▍   | 60/94 [00:09<00:05,  6.22it/s]\u001b[A\n",
            "doing validation:  64%|██████▍   | 60/94 [00:09<00:05,  6.22it/s]\u001b[A\n",
            "doing validation:  65%|██████▍   | 61/94 [00:09<00:05,  6.23it/s]\u001b[A\n",
            "doing validation:  65%|██████▍   | 61/94 [00:09<00:05,  6.23it/s]\u001b[A\n",
            "doing validation:  66%|██████▌   | 62/94 [00:10<00:05,  6.23it/s]\u001b[A\n",
            "doing validation:  66%|██████▌   | 62/94 [00:10<00:05,  6.23it/s]\u001b[A\n",
            "doing validation:  67%|██████▋   | 63/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  67%|██████▋   | 63/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  68%|██████▊   | 64/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  68%|██████▊   | 64/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  69%|██████▉   | 65/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  69%|██████▉   | 65/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  70%|███████   | 66/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  70%|███████   | 66/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  71%|███████▏  | 67/94 [00:10<00:04,  6.24it/s]\u001b[A\n",
            "doing validation:  71%|███████▏  | 67/94 [00:10<00:04,  6.24it/s]\u001b[A\n",
            "doing validation:  72%|███████▏  | 68/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  72%|███████▏  | 68/94 [00:10<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  73%|███████▎  | 69/94 [00:11<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  73%|███████▎  | 69/94 [00:11<00:04,  6.23it/s]\u001b[A\n",
            "doing validation:  74%|███████▍  | 70/94 [00:11<00:03,  6.23it/s]\u001b[A\n",
            "doing validation:  74%|███████▍  | 70/94 [00:11<00:03,  6.23it/s]\u001b[A\n",
            "doing validation:  76%|███████▌  | 71/94 [00:11<00:03,  6.23it/s]\u001b[A\n",
            "doing validation:  76%|███████▌  | 71/94 [00:11<00:03,  6.23it/s]\u001b[A\n",
            "doing validation:  77%|███████▋  | 72/94 [00:11<00:03,  6.24it/s]\u001b[A\n",
            "doing validation:  77%|███████▋  | 72/94 [00:11<00:03,  6.24it/s]\u001b[A\n",
            "doing validation:  78%|███████▊  | 73/94 [00:11<00:03,  6.24it/s]\u001b[A\n",
            "doing validation:  78%|███████▊  | 73/94 [00:11<00:03,  6.24it/s]\u001b[A\n",
            "doing validation:  79%|███████▊  | 74/94 [00:11<00:03,  6.24it/s]\u001b[A\n",
            "doing validation:  79%|███████▊  | 74/94 [00:11<00:03,  6.24it/s]\u001b[A\n",
            "doing validation:  80%|███████▉  | 75/94 [00:12<00:03,  6.23it/s]\u001b[A\n",
            "doing validation:  80%|███████▉  | 75/94 [00:12<00:03,  6.23it/s]\u001b[A\n",
            "doing validation:  81%|████████  | 76/94 [00:12<00:02,  6.22it/s]\u001b[A\n",
            "doing validation:  81%|████████  | 76/94 [00:12<00:02,  6.22it/s]\u001b[A\n",
            "doing validation:  82%|████████▏ | 77/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  82%|████████▏ | 77/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  83%|████████▎ | 78/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  83%|████████▎ | 78/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  84%|████████▍ | 79/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  84%|████████▍ | 79/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  85%|████████▌ | 80/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  85%|████████▌ | 80/94 [00:12<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  86%|████████▌ | 81/94 [00:13<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  86%|████████▌ | 81/94 [00:13<00:02,  6.21it/s]\u001b[A\n",
            "doing validation:  87%|████████▋ | 82/94 [00:13<00:01,  6.22it/s]\u001b[A\n",
            "doing validation:  87%|████████▋ | 82/94 [00:13<00:01,  6.22it/s]\u001b[A\n",
            "doing validation:  88%|████████▊ | 83/94 [00:13<00:01,  6.22it/s]\u001b[A\n",
            "doing validation:  88%|████████▊ | 83/94 [00:13<00:01,  6.22it/s]\u001b[A\n",
            "doing validation:  89%|████████▉ | 84/94 [00:13<00:01,  6.20it/s]\u001b[A\n",
            "doing validation:  89%|████████▉ | 84/94 [00:13<00:01,  6.20it/s]\u001b[A\n",
            "doing validation:  90%|█████████ | 85/94 [00:13<00:01,  6.20it/s]\u001b[A\n",
            "doing validation:  90%|█████████ | 85/94 [00:13<00:01,  6.20it/s]\u001b[A\n",
            "doing validation:  91%|█████████▏| 86/94 [00:13<00:01,  6.21it/s]\u001b[A\n",
            "doing validation:  91%|█████████▏| 86/94 [00:13<00:01,  6.21it/s]\u001b[A\n",
            "doing validation:  93%|█████████▎| 87/94 [00:14<00:01,  6.21it/s]\u001b[A\n",
            "doing validation:  93%|█████████▎| 87/94 [00:14<00:01,  6.21it/s]\u001b[A\n",
            "doing validation:  94%|█████████▎| 88/94 [00:14<00:00,  6.21it/s]\u001b[A\n",
            "doing validation:  94%|█████████▎| 88/94 [00:14<00:00,  6.21it/s]\u001b[A\n",
            "doing validation:  95%|█████████▍| 89/94 [00:14<00:00,  6.22it/s]\u001b[A\n",
            "doing validation:  95%|█████████▍| 89/94 [00:14<00:00,  6.22it/s]\u001b[A\n",
            "doing validation:  96%|█████████▌| 90/94 [00:14<00:00,  6.22it/s]\u001b[A\n",
            "doing validation:  96%|█████████▌| 90/94 [00:14<00:00,  6.22it/s]\u001b[A\n",
            "doing validation:  97%|█████████▋| 91/94 [00:14<00:00,  6.23it/s]\u001b[A\n",
            "doing validation:  97%|█████████▋| 91/94 [00:14<00:00,  6.23it/s]\u001b[A\n",
            "doing validation:  98%|█████████▊| 92/94 [00:14<00:00,  6.23it/s]\u001b[A\n",
            "doing validation:  98%|█████████▊| 92/94 [00:14<00:00,  6.23it/s]\u001b[A\n",
            "doing validation:  99%|█████████▉| 93/94 [00:15<00:00,  6.23it/s]\u001b[A\n",
            "doing validation:  99%|█████████▉| 93/94 [00:15<00:00,  6.23it/s]\u001b[A\n",
            "                                                                 \u001b[A\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:06<00:56,  6.23s/it]\u001b[A\n",
            " 20%|██        | 2/10 [00:12<00:49,  6.23s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:18<00:43,  6.23s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:24<00:37,  6.24s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [00:31<00:31,  6.23s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [00:33<00:20,  5.02s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [00:40<00:16,  5.41s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [00:46<00:11,  5.68s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:52<00:05,  5.87s/it]\u001b[A\n",
            "100%|██████████| 10/10 [00:58<00:00,  6.01s/it]\u001b[A\n",
            "100%|██████████| 1/1 [08:15<00:00, 495.32s/it] \u001b[A\n"
          ]
        }
      ],
      "source": [
        "wandb.init(project=\"alpaca_ft1\", # the project I am working on\n",
        "           tags=[\"baseline\",\"7b\"],\n",
        "           job_type=\"train\",\n",
        "           config=config) # the Hyperparameters I want to keep track of\n",
        "\n",
        "# Training\n",
        "acc = Accuracy()\n",
        "model.train()\n",
        "train_step = 0\n",
        "for epoch in tqdm(range(config.epochs)):\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        batch = to_gpu(batch)\n",
        "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "            out = model(**batch)\n",
        "            loss = loss_fn(out.logits, batch[\"labels\"]) / config.gradient_accumulation_steps  # you could use out.loss and not shift the dataset\n",
        "            loss.backward()\n",
        "        if step%config.gradient_accumulation_steps == 0:\n",
        "            # we can log the metrics to W&B\n",
        "            wandb.log({\"train/loss\": loss.item() * config.gradient_accumulation_steps,\n",
        "                       \"train/accuracy\": acc.update(out.logits, batch[\"labels\"]),\n",
        "                       \"train/learning_rate\": scheduler.get_last_lr()[0],\n",
        "                       \"train/global_step\": train_step})\n",
        "            optim.step()\n",
        "            scheduler.step()\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "            train_step += 1\n",
        "    validate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBB3KSjREQdN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPpBDxCMUzVV",
        "outputId": "9dd16f2c-14bf-4887-be5d-53c88ea288b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>train/accuracy</td><td>▃▁▄▄▅▆▇▆▆▅▆▅▄▅▃▅▂▆▅▆▇█▆█▅▄▅▅▆▆▇▇▅▇▅▆▅▆▆▆</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▆█▆▄▄▂▂▃▃▄▃▃▃▃▄▃▅▃▄▃▂▁▂▁▄▄▃▃▂▂▂▂▃▂▂▂▃▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68754</td></tr><tr><td>eval/loss</td><td>1.28682</td></tr><tr><td>train/accuracy</td><td>0.69922</td></tr><tr><td>train/global_step</td><td>285</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.22575</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">whole-sun-22</strong> at: <a href='https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8v0vppzk' target=\"_blank\">https://wandb.ai/llm-finetune-wb/alpaca_ft1/runs/8v0vppzk</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240310_174309-8v0vppzk/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# we save the model checkpoint at the end\n",
        "save_model(model, model_name=config.model_id.replace(\"/\", \"_\"), models_folder=\"models/\", log=config.log_model)\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mP05cnSEQdN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "394212d4ac134ffaaa1f14fbaa05d699": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1828eb49124630b322d5968827ec99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_920f9331c34d485d9e8d641e01a70876",
              "IPY_MODEL_5484e3031b184d78905c5fc82dca5527"
            ],
            "layout": "IPY_MODEL_907cbed0937a44a7aaac97d93e62d786"
          }
        },
        "5484e3031b184d78905c5fc82dca5527": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e025f7044f48ae8081448aaf94d4c0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffe4a8ffcb7e445cbf41d3c1ba1706f5",
            "value": 1
          }
        },
        "60d38fa9166043228a2e0730b4e8dc01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6984f73d35cf4ac6bf6f315920e3790c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394212d4ac134ffaaa1f14fbaa05d699",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a13d15ad3d8f45478bf690a2af5fb307",
            "value": 1
          }
        },
        "70b079708aab4a4ebfaebcb551a4d56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73fdd939d0c449389bd1504adb894820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e025f7044f48ae8081448aaf94d4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f7085f00b44fec8d956c9a91ba6ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a9de5faa2b4234ba96dd5ab768fc14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "907cbed0937a44a7aaac97d93e62d786": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920f9331c34d485d9e8d641e01a70876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a9de5faa2b4234ba96dd5ab768fc14",
            "placeholder": "​",
            "style": "IPY_MODEL_70b079708aab4a4ebfaebcb551a4d56b",
            "value": "45.988 MB of 45.988 MB uploaded\r"
          }
        },
        "a13d15ad3d8f45478bf690a2af5fb307": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab3d4413dc6b45708f218e9862c569b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c23a39eb46b64c91baa2f70a766a0606",
              "IPY_MODEL_6984f73d35cf4ac6bf6f315920e3790c"
            ],
            "layout": "IPY_MODEL_60d38fa9166043228a2e0730b4e8dc01"
          }
        },
        "c23a39eb46b64c91baa2f70a766a0606": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f7085f00b44fec8d956c9a91ba6ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_73fdd939d0c449389bd1504adb894820",
            "value": "45.309 MB of 45.309 MB uploaded (1.523 MB deduped)\r"
          }
        },
        "ffe4a8ffcb7e445cbf41d3c1ba1706f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}